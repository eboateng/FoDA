{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changelog\n",
    "1. Introduction\n",
    "2. Changed all variable names for consistency\n",
    "3. Added 1.3 limitations dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEN163A - Fundamentals of Data Analytics\n",
    "# Assignment 3 - Large-scale Internet Data Analysis\n",
    "### Ir. Jacopo De Stefani - [J.deStefani@tudelft.nl](mailto:J.deStefani@tudelft.nl)\n",
    "### Joao Pizani Flor, M.Sc. - [J.p.pizaniflor@tudelft.nl](mailto:J.p.pizaniflor@tudelft.nl)\n",
    "\n",
    "### 01-04-2022\n",
    "## Group 2\n",
    "- Emmanuel M Boateng - '5617642'\n",
    "- Joost Oortwijn - '4593472'\n",
    "- Philip Busscher - ''4611993''\n",
    "- Floris Kool - ''4975243''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Tabularazor inc. is a large national newspaper covering many differenttopics. The company suffered an electrical malfunction causing a loss of archived data. Luckily they have a backup prepared of the articles published over the last couple of years. The backup from Tabularazor inc. contains the articles sorted by month and year, including the authors of the articles and the publishing day and time. In this assignment we will use this metadata to deduce some interesting facts about Tabularazors employees.\n",
    "\n",
    "**Problem description** <br>\n",
    "For this assignment we want to answer the following questions:<br>\n",
    "a. Are there couples among the employees? <br>\n",
    "b. Did any of the employees have childeren?<br>\n",
    "c. How many holidays does an employee have?<br>\n",
    "\n",
    "The problem with answering these questions is the fact that there is only metadata available. In other words, the available data can not directly answer these questions. But, based on our own interpretation of the available metadata, we can answer these questions. This interpretation will be eleborated on below in chapter 2.\n",
    "\n",
    "We will start by describing how the data is retrieved from the backup using webscraping and describing the available data in chapter 1. After this, in chapter 2, the data is analyzed and conclusions will be drawn which are usefull for answering the above named questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset description\n",
    "\n",
    "The provided dataset contains an archief of a newpaper company with publications from to year 2012 till 2019. Per article, the publication date, publication time and the responsible author are included within the dataset. Based on these three attributes further analysis will be conducted.\n",
    "\n",
    "The data can be found on a website (https://jdestefani.github.io/SEN163A-TabularRazorArchives/). That means that the data is stored on a webserver and a specific approach is required to obtain the data in the form of an HTML file. This process is called webscraping. To enable webscraping the python library Beautifulsoup is selected. This library contains the tools to work with HTML files like the provided data. Though, to obtain the data from the webserver, another library is necessary to generate HTTP requests. This library is called: requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cell belows needs to be run for the table alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globally used variable names\n",
    "complete_df - Dataframe with the author name, date and time for every article\n",
    "\n",
    "employees_df - Dataframe with for each author and each day a field containing:\n",
    " - (0) not_employed\n",
    " - (1) Working\n",
    " - (2) Offday\n",
    " - (3) weekend_Working\n",
    " - (4) weekend_Offday\n",
    " \n",
    "potential_couples - List of all possible pairs of two authors\n",
    "\n",
    "couples_df - Dataframe with the following information for each author:\n",
    " - Number of days at least one of the couple wasn't employed\n",
    " - Number of days both people were working\n",
    " - Number of days only one of the couple was working\n",
    " - Number of days neither people were working during a weekend\n",
    " - Number of days neither people were working on a workday\n",
    " - ratio of days worked together over days that one person was working\n",
    " - ratio of days they were off together over days that only one person was off\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'removeprefix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ea92ee6f8a66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Get file name of pkl file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0myear_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myear_link\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0myear_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myear_filename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremoveprefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0myear_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myear_filename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremovesuffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0myear_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0myear_filename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'removeprefix'"
     ]
    }
   ],
   "source": [
    "#READING MAIN PAGE\n",
    "#Get file\n",
    "source_link = \"https://jdestefani.github.io/SEN163A-TabularRazorArchives/\"\n",
    "response = requests.get(source_link)\n",
    "\n",
    "#Read main file\n",
    "main_page = BeautifulSoup(response.text)\n",
    "\n",
    "for year_link in main_page.find_all('a', href=True):\n",
    "    #READING YEAR PAGE & SAVING PKL FILE FOR EACH YEAR\n",
    "    \n",
    "    #Get file name of pkl file\n",
    "    year_filename = year_link.get('href')\n",
    "    year_filename = year_filename.removeprefix('./')\n",
    "    year_filename = year_filename.removesuffix('.html')\n",
    "    year_filename = \"data/\" + year_filename + \".pkl\"\n",
    "    \n",
    "    #Clear lists of data for each year\n",
    "    data_tuple = []\n",
    "    \n",
    "    #Get file  \n",
    "    year_link = urljoin(source_link, year_link.get('href')) \n",
    "    response = requests.get(year_link)\n",
    "    \n",
    "    #Read year file\n",
    "    year_page = BeautifulSoup(response.text)\n",
    "     \n",
    "    for month_link in year_page.find_all('a', href=True):\n",
    "        #Get file\n",
    "        month_link = urljoin(year_link, month_link.get('href'))\n",
    "        response = requests.get(month_link)\n",
    "        \n",
    "        #Read month file\n",
    "        month_page = BeautifulSoup(response.text)\n",
    "        i = 0\n",
    "        \n",
    "        start  = time.time()\n",
    "        \n",
    "        for article_link in month_page.find_all('a', href=True):        \n",
    "            #Get file\n",
    "            article_link = urljoin(month_link, article_link.get('href')) \n",
    "            response = requests.get(article_link)\n",
    "        \n",
    "            #Read article file\n",
    "            article_page = BeautifulSoup(response.text)\n",
    "                       \n",
    "            for div_element in article_page.find_all('div'):\n",
    "                if div_element.get('class') == ['author']:\n",
    "                    article_author = div_element.get_text()\n",
    "                if div_element.get('class') == ['date']:\n",
    "                    article_date = div_element.get_text()\n",
    "                if div_element.get('class') == ['time']:\n",
    "                    article_time = div_element.get_text()\n",
    "\n",
    "            #Add data\n",
    "            data_tuple.append((article_author, article_date, article_time))\n",
    "            i += 1 \n",
    "            #if i >= 10:\n",
    "            #    break\n",
    "        \n",
    "        #Print after each month\n",
    "        dur = round(time.time() - start,2)\n",
    "        print('Read: ' + month_link)\n",
    "        print('Added: ' + str(i) + ' articles')\n",
    "        print('Duration: ' + str(dur) + ' seconds')\n",
    "        \n",
    "        #break\n",
    "\n",
    "    #Save file after each year\n",
    "    print()\n",
    "    print(\"---\")\n",
    "    print(\"Saving: \" + year_filename)\n",
    "    df = pd.DataFrame(data_tuple)\n",
    "    df.to_pickle(year_filename)\n",
    "    print(\"Saved: \" + str(len(df[0])) + \" articles\")\n",
    "    print(\"---\")\n",
    "    print()\n",
    "    \n",
    "    #break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Opening the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete_df = pickle.load(open(\"2012_2019.pkl\", \"rb\")) # use this as examiner\n",
    "complete_df = pickle.load(open(\"data/2012_2019.pkl\", \"rb\"))\n",
    "complete_df = complete_df.reset_index()\n",
    "complete_df = complete_df.drop(['index'], axis=1) \n",
    "complete_df.columns = ['Author','Date','Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Limitations dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beforehand we must check if the dataset is clean and useable for the analysis. Therefore we check if the columns of interest contain the right value types and we check if there are NaN values in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are missing errors in the dataset\n",
    "complete_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if only date times in column \"date\"\n",
    "complete_df['Date'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if only strings in column \"author\"\n",
    "complete_df['Author'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the check above we found no limitations in the dataset which could influence the analysis. All values had the expected datatype suitable for analyzing and also no NaN values are found in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Analysis\n",
    "\n",
    "The following analysis focuses on investigating how colleagues at Tubularazor are related to each other. By looking at the author names and publication dates of the articles, certain patterns can be observed. These patterns are able to clearify what kind of relations the employees have with respect to each other. We will look to find couples within Tubularazor authors, whether an author has had extended leave due to a possible child birth and the average amount of holidays for employees of Tubularazor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Tranform data\n",
    "\n",
    "We will start by transforming the raw data into a dataset useful for our analysis questions. For our analysis we only need to know for each author on what day they have posted an article. This way we can deduce on what days people were working, which will be used in the questions.\n",
    "\n",
    "After doing this we can add some extra information. An author might not be employed throughout the entire period that we're analyzing. We're using the date they first and last posted to deduce when someone might have started or stopped working for Trebularazor. We also noticed that there are significantly less articles posted in the weekend. We also want to include this information. The result is a dataset with a field for each author on each day that can have the following value:\n",
    "- Not employed\n",
    "- Working\n",
    "- Day off\n",
    "- Working on weekend\n",
    "- weekend day off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with all the publication dates per author\n",
    "merged_groupby = complete_df.groupby(['Author'])['Date'].unique().apply(list).reset_index()\n",
    "merged_groupby = merged_groupby.set_index('Author')\n",
    "\n",
    "# Split the list with publication dates to a column\n",
    "split_df = pd.DataFrame(merged_groupby['Date'].tolist())\n",
    "split_df = split_df.set_index(merged_groupby.index)\n",
    "split_df = split_df.astype(str)\n",
    "\n",
    "# Create range of dates from the beginning of 2012 till the end of 20190\n",
    "start = datetime.datetime.strptime(\"2012-1-1\", \"%Y-%m-%d\")\n",
    "end = datetime.datetime.strptime(\"2019-12-31\", \"%Y-%m-%d\")\n",
    "date_generated = pd.date_range(start, end)\n",
    "\n",
    "# Create new dataframe with only zero's \n",
    "zero_df = pd.DataFrame(np.zeros((len(split_df), len(date_generated)), np.uint8))\n",
    "zero_df = zero_df.set_index(merged_groupby.index)\n",
    "zero_df.columns = date_generated\n",
    "zero_df.columns = zero_df.columns.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the new dataframe (with zero's) with ones in case an author has published on a specific date\n",
    "list_index = list(split_df.index.values)\n",
    "\n",
    "for i in list_index:\n",
    "    for j in range(split_df.shape[1]):\n",
    "        date = split_df.loc[i,j]\n",
    "        if np.isnat(np.datetime64(date))==True:\n",
    "            break\n",
    "        else:\n",
    "            zero_df.loc[i,date]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe with all employees and all days containing:\n",
    "\n",
    "\n",
    "| Value in dataframe     | Meaning |\n",
    "| ----------- | ----------- |\n",
    "| 0      | not_employed       |\n",
    "| 1   | Working        |\n",
    "| 2   | Offday        |\n",
    "| 3   | weekend_Working        |\n",
    "| 4   | weekend_Offday        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe\n",
    "#Fill with not_employed until their first publication\n",
    "#Fill with workdays and offdays based on publication\n",
    "employees_data = []\n",
    "\n",
    "for employee in zero_df.iterrows():\n",
    "    days = []\n",
    "    startedworking = False\n",
    "    \n",
    "    for day in employee[1]:\n",
    "        if day == 1:\n",
    "            startedworking = True\n",
    "            days.append(1) #Working\n",
    "        else:\n",
    "            if startedworking:\n",
    "                days.append(2) #Offday\n",
    "            else:\n",
    "                days.append(0) #not_employed\n",
    "    \n",
    "    employees_data.append(days)\n",
    "                \n",
    "employees_df = pd.DataFrame(employees_data, columns = date_generated.strftime(\"%Y-%m-%d\"))\n",
    "employees_df.index = zero_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill not employed based on last publication day\n",
    "rowindex = 0\n",
    "\n",
    "for employee in employees_df.iterrows():    \n",
    "    \n",
    "    #Run through the days reversed to find last publication day\n",
    "    columnindex = len(employee[1])\n",
    "    \n",
    "    for day in reversed(employee[1]): \n",
    "        columnindex -= 1\n",
    "\n",
    "        if day == 1:\n",
    "            break\n",
    "        else:        \n",
    "            employees_df.iat[rowindex,columnindex] = 0 #not_employed    \n",
    "            \n",
    "    rowindex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change weekend days to right lables\n",
    "from datetime import datetime\n",
    "for i in list(employees_df.index.values):\n",
    "    for j in list(employees_df.columns):\n",
    "        year = int(j[:4])\n",
    "        month = int(j[5:7])\n",
    "        day = int(j[-2:])\n",
    "        date = datetime(year,month,day)\n",
    "        if date.weekday() > 4:\n",
    "            if employees_df.loc[i,j] == 1:\n",
    "                employees_df.loc[i,j] = 3 #weekend_Working\n",
    "            elif employees_df.loc[i,j] == 2:\n",
    "                employees_df.loc[i,j] = 4 #weekend_Offday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Couple among employees (Question a)\n",
    "\n",
    "The first test that will be conducted is whether there are couples among the authors and if they are still together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-68e12a25b29f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Create list of all potential couples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauthors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpotential_couples\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0mcouple\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcouple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'merged' is not defined"
     ]
    }
   ],
   "source": [
    "#Create list of all potential couples\n",
    "authors = set(merged['Author'])\n",
    "potential_couples =  [couple for couple in combinations(authors,2)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe with all couple of employees containing:\n",
    " - Number of days at least one of the couple wasn't employed\n",
    " - Number of days both people were working\n",
    " - Number of days only one of the couple was working\n",
    " - Number of days neither people were working during a weekend\n",
    " - Number of days neither people were working on a workday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'potential_couples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-94803cfbc9e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#Check for all couples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpotential_couple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpotential_couples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#Reset counters for each couple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'potential_couples' is not defined"
     ]
    }
   ],
   "source": [
    "#LOADING WILL TAKE SOME TIME (2-3 minutes)\n",
    "\n",
    "not_employed = []\n",
    "both_working = []\n",
    "one_working = []\n",
    "weekend = []\n",
    "offdays = []\n",
    "couples_data = []\n",
    "\n",
    "start  = time.time()\n",
    "\n",
    "#Check for all couples\n",
    "for potential_couple in potential_couples:\n",
    "    \n",
    "    #Reset counters for each couple\n",
    "    not_employed_count = 0\n",
    "    both_working_count = 0\n",
    "    one_working_count = 0\n",
    "    weekend_count = 0\n",
    "    offdays_count = 0\n",
    "    templist = []\n",
    "    \n",
    "    #Select couple\n",
    "    temp_df = employees_df.loc[[potential_couple[0],potential_couple[1]]]\n",
    "    \n",
    "    for column in temp_df:\n",
    "        \n",
    "        #Checking both employees for:\n",
    "        #0 - not_employed\n",
    "        #1 - Working\n",
    "        #2 - Offday\n",
    "        #3 - weekend_Working\n",
    "        #4 - weekend_Offday\n",
    "        \n",
    "        #Add 1 to counter based on conditions mentioned in cell above\n",
    "        if temp_df[column][0] == 0 or temp_df[column][1] == 0:\n",
    "            not_employed_count += 1\n",
    "        elif (temp_df[column][0] == 1 and temp_df[column][1] == 1) or (temp_df[column][0] == 3 and temp_df[column][1] == 3):\n",
    "            both_working_count += 1\n",
    "        elif (temp_df[column][0] == 1 or temp_df[column][1] == 1) or (temp_df[column][0] == 3 or temp_df[column][1] == 3):\n",
    "            one_working_count += 1\n",
    "        elif temp_df[column][0] == 4 and temp_df[column][1] == 4:\n",
    "            weekend_count += 1\n",
    "        else:\n",
    "            offdays_count += 1\n",
    "    \n",
    "    #Add employee count data to tuple of lists\n",
    "    templist.append(not_employed_count)\n",
    "    templist.append(both_working_count)\n",
    "    templist.append(one_working_count)\n",
    "    templist.append(weekend_count)\n",
    "    templist.append(offdays_count)           \n",
    "    couples_data.append((templist))\n",
    "\n",
    "#Create dataframe of all couples      \n",
    "couples_df = pd.DataFrame(couples_data, columns = ['Not employed', 'Both working', 'One working', 'weekend', 'Off days'])\n",
    "couples_df.index = potential_couples[:len(couples_data)]\n",
    "\n",
    "dur = round(time.time() - start,2)\n",
    "print(\"Loading took: \" + str(dur) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if two people are a \"couple\" we assume they often work together and often take days off together. For all potential couples we will calculate two ratio's:\n",
    "1. Days worked togeter over days that at least one person was working\n",
    "2. Off days together over days that at least one person was not working\n",
    "\n",
    "After some testing we noticed significant influences of days that people were unemployed and weekend days. If people were both not working for Trebulazor they had many \"days off\" together, by including the weekends we also had higher ratio's of people having many \"days off\" together. This is why we categorized these values in 2.1 and filtered for them in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freetogether_ratio = []\n",
    "worktogether_ratio = []\n",
    "\n",
    "#Calculate ratio's for each couple by:\n",
    "#Free days/ (Free days + One person working days)\n",
    "#Both people working days/ (Both people working days + One person working days)\n",
    "\n",
    "for potential_couple in couples_df.iterrows():\n",
    "    \n",
    "    #Added a divide by 0 check\n",
    "    if potential_couple[1]['Off days'] + potential_couple[1]['One working'] != 0:\n",
    "        freetogether_ratio.append(potential_couple[1]['Off days']/(potential_couple[1]['Off days'] + potential_couple[1]['One working']))\n",
    "    else:\n",
    "        freetogether_ratio.append(0)\n",
    "    \n",
    "    #Added a divide by 0 check\n",
    "    if potential_couple[1]['Both working'] + potential_couple[1]['One working'] != 0:\n",
    "        worktogether_ratio.append(potential_couple[1]['Both working']/(potential_couple[1]['Both working'] + potential_couple[1]['One working']))\n",
    "    else:\n",
    "        worktogether_ratio.append(0)\n",
    "\n",
    "couples_df['free_ratio'] = freetogether_ratio\n",
    "couples_df['work_ratio'] = worktogether_ratio\n",
    "\n",
    "#couples_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the distribution of ratio's to help find couples\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "axs[0].hist(couples_df['free_ratio'], bins=20)\n",
    "axs[1].hist(couples_df['work_ratio'], bins=20)\n",
    "\n",
    "axs[0].set(xlabel='ratio', ylabel='=Frequency',\n",
    "       title='Free days ratio')\n",
    "axs[1].set(xlabel='ratio', ylabel='=Frequency',\n",
    "       title='Work days ratio')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples = []\n",
    "\n",
    "#Cutoff values:\n",
    "free_ratio = 0.5\n",
    "work_ratio = 0.5\n",
    "\n",
    "#Add couples with ratio's higher than the cutoff values\n",
    "for potential_couple in couples_df.iterrows():\n",
    "    if potential_couple[1]['free_ratio'] >= free_ratio and potential_couple[1]['work_ratio'] >= work_ratio:\n",
    "        couples.append(potential_couple[0])\n",
    "\n",
    "print(len(couples))\n",
    "\n",
    "temp_df = couples_df.loc[couples]\n",
    "\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "To check which pair of authors might be a couple we use the ratio's described earlier. Using the cutoff values (in the cell above) we could set different thresholds for what a couple is and how often they would need to work together or take days off together. Before removing the weekend and not employed days we noticed many potential couples and changing the cutoff values changed the outcomes. \n",
    "\n",
    "After removing the weekend and not employed days however we only noticed one clear outlier: Grover Gibbons & Augusta Beltrami. Out of the 739 days they were working 695 days were worked together (94%) and out of 132 holidays 88 were at the same time (67%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Children (Question b)\n",
    "*Did any of the employees have a child? If so, who?*\n",
    "\n",
    "To deduce whether someone had a child we can use the number of days that people were not publishing for Tabularazor. Though we can only speculate why a person has a long period between publishing we will asume that if a person is away for longer than 80 days she is away for pregnancy leave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find max time employees pauses for all employees\n",
    "\n",
    "employees = complete_df['Author'].unique().tolist()\n",
    "d = []\n",
    "for names in employees:\n",
    "    df_f =  complete_df.loc[complete_df['Author']==names]\n",
    "    diff = df_f['Date'].diff().max()\n",
    "    #print(diff)\n",
    "    d.append([names,diff])\n",
    "    #print(names, df_f['Date'].diff().max())\n",
    "\n",
    "#create a dataframe from the list\n",
    "overview = pd.DataFrame(d,columns=['Author', 'Max_Absence'])\n",
    "#convert to int\n",
    "overview['Max_Absence'] = overview['Max_Absence'].dt.days\n",
    "#sort the values\n",
    "overview = overview.sort_values(by='Max_Absence', ascending=False)\n",
    "\n",
    "#show the head.\n",
    "overview.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Looking at the maximum time between publishing dates their are two clear outliers: Corrine Gallop and Marthe Hale. Both having around 130 days leave, with the 3rd highest time between posting being only 25 days. As mentioned earlier there could be many causes for this time between posting, but we will asume Corrine Gallop and Marthe Hale were on pregnancy leave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Holidays (Question c)\n",
    "*If you would be looking to work for Tabularazor Inc., how many holidays can you expect to get per\n",
    "year?*\n",
    "\n",
    "To answer how many holidays a person can expect when working at Tabularazor we will look at the amount of days an author was not publishing, ignoring the weekend days and days not employed. To do this we checked for each employee the ratio of days off over the days the employee is \"supposed\" to work. For each extra day worked in the weekend we substracted a holiday as the employee then worked more than the standard work days.\n",
    "\n",
    "After calculating the ratio's we multiply this by the standard number of yearly working days to find the average amount of yearly holidays for each employee. To calculate the total average yearly holidays we calculated the average of all the employees average yearly holidays.\n",
    "\n",
    "This method was useful for finding the average yearly holidays per employee. However to calculate the average of all employees it's more accurate to look at the total working days of all employees and days off of all employees. This way employees that worked at Tabularazor longer have more influence over the average than a person only working there temporary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_days = []\n",
    "work_days = []\n",
    "ratios = []\n",
    "yearly_holidays = []\n",
    "\n",
    "#Amount of non weekend days per year\n",
    "yearly_work_days = (5 *365/7)\n",
    "\n",
    "\n",
    "for employee in employees_df.iterrows():    \n",
    "    \n",
    "    off_days = 0\n",
    "    work_days = 0\n",
    "    \n",
    "    for day in employee[1]: \n",
    "        \n",
    "        #Checking employee days for:\n",
    "        #0 - not_employed\n",
    "        #1 - Working\n",
    "        #2 - Offday\n",
    "        #3 - weekend_Working\n",
    "        #4 - weekend_Offday\n",
    "        \n",
    "        #Count the working days when this employee was employed\n",
    "        if day != 0 and day != 4:\n",
    "            work_days += 1\n",
    "        #Count days off\n",
    "        if day == 2:\n",
    "            off_days += 1\n",
    "        #Remove extra days worked from off days\n",
    "        elif day == 3:\n",
    "            off_days-= 1\n",
    "    \n",
    "    off_days.append(off_days)\n",
    "    work_days.append(work_days)\n",
    "    \n",
    "    ratio = off_days/work_days\n",
    "    ratios.append(ratio)\n",
    "    \n",
    "    yearly_holidays.append(round(ratio * yearly_work_days))\n",
    " \n",
    "employees_df[\"Off days\"] = off_days\n",
    "employees_df[\"Work days\"] = work_days\n",
    "employees_df[\"Off day ratio\"] = ratios\n",
    "employees_df[\"Yearly holidays\"] = yearly_holidays\n",
    "\n",
    "Average_Holidays = round(employees_df[\"Yearly holidays\"].mean())\n",
    "\n",
    "print(\"Average yearly holidays: \" + str(Average_Holidays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of yearly holidays per employee is 31. However by looking at the results in the dataframe *employees_df* that some employees get much more days off. Roughly speaking people that worked there less (likely temporary writers) get more days off. Though, there are also other factors influencing this like extra leave due to pregnancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_days = 0\n",
    "work_days = 0\n",
    "\n",
    "for employee in employees_df.iterrows():    \n",
    "        \n",
    "    for day in employee[1]: \n",
    "        \n",
    "        #Checking employee days for:\n",
    "        #0 - not_employed\n",
    "        #1 - Working\n",
    "        #2 - Offday\n",
    "        #3 - weekend_Working\n",
    "        #4 - weekend_Offday\n",
    "        \n",
    "        #Count the working days when this employee was employed\n",
    "        if day != 0 and day != 4:\n",
    "            work_days += 1\n",
    "        #Count days off\n",
    "        if day == 2:\n",
    "            off_days += 1\n",
    "        #Remove extra days worked from off days\n",
    "        elif day == 3:\n",
    "            off_days -= 1\n",
    "            \n",
    "ratio = off_days/work_days\n",
    "\n",
    "#print(off_days)\n",
    "#print(work_days)\n",
    "#print(ratio)\n",
    "\n",
    "yearly_work_days = (5 *365/7)\n",
    "\n",
    "Average_Holidays = round(yearly_work_days * ratio)\n",
    "\n",
    "print(\"Average yearly holidays: \" + str(Average_Holidays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "When taking into account how long each author worked at the company we get a slightly lower number of average yearly holiday days: 29 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
