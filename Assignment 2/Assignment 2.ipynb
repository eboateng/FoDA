{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83ed52d",
   "metadata": {},
   "source": [
    "# Changelog\n",
    "Reporting:\n",
    "- Rewritten introduction\n",
    "- Rewritten dataset description\n",
    "- Created seperate headings for Variable descriptions and EU list\n",
    "- Added text explaining AS and Probe merge\n",
    "- Added chapter 2 introduction\n",
    "- Added chapter 2.1 conclusion\n",
    "- Added chapter 2.2 conclusion\n",
    "- Added chapter 2.3 conclusion\n",
    "- Added chapter 2.4 conclusion\n",
    "\t\n",
    "Analysis\n",
    "- Changed EL to GR in EU_List\n",
    "- Loaded all 24 files of RIPE data (We previously loaded only the first 6 due to time constraints)\n",
    "- Changed the AS/Probe dataset limitations. Now shows probes with ASNs not in ASN dataset and shows amount of ASNs being used for analysis\n",
    "- Included negative ping checks in RIPE dataset limitation description\n",
    "- Added number of probes in RIPE dataset bigger than number of probes in probe dataset to limitation description\n",
    "- Added table of minimal latency from selected set to each country\n",
    "- Added ASN locations of selected to support conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb46204f",
   "metadata": {},
   "source": [
    "# SEN163A - Fundamentals of Data Analytics\n",
    "# Assignment 2 - Large-scale Internet Data Analysis\n",
    "### Ir. Jacopo De Stefani - [J.deStefani@tudelft.nl](mailto:J.deStefani@tudelft.nl)\n",
    "### Joao Pizani Flor, M.Sc. - [J.p.pizaniflor@tudelft.nl](mailto:J.p.pizaniflor@tudelft.nl)\n",
    "\n",
    "### 08-04-2022\n",
    "## Group 2\n",
    "- Emmanuel M Boateng - '5617642'\n",
    "- Joost Oortwijn - '4593472'\n",
    "- Philip Busscher - ''4611993''\n",
    "- Floris Kool - ''4975243''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b733b0",
   "metadata": {},
   "source": [
    "# Introduction & problem description\n",
    "The Groote Nationale Investeer (GNI) Bank has given us the assignment to find the four best datacenter locations for their expansion into the mobile banking sector. To do this we will use data analytics to find the 4 locations that overall give the lowest latency to all EU countries. To analyze this we will use Atlas RIPE ping dataset. This dataset uses probes that measure different internet metrics at a lot of different locations, chapter one will explain this in more detail. To accomplish our analysis this we will go through five steps:\n",
    "\n",
    "1. Load all the data nessesary and describe potential limitations in the available data.\n",
    "2. Transform and combine the datasets so we have the right probes selected and only contain the information needed for analysis.\n",
    "3. Find all measurement data from the selected probes to EU countries, from a subset of the complete dataset.\n",
    "4. Calculate the average latency from each measurement probe to each country.\n",
    "5. Find the 4 locations that give the best latency to all eu countries and provide a conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d255137",
   "metadata": {},
   "source": [
    "# 1. Dataset description\n",
    "\n",
    "The Atlas RIPE dataset uses a large number of probes to measure different internet metrics. We use their ping dataset, which contains latency data from all of their probes to various IP adresses. Their ping dataset is stored in a seperate file for each hour, containing about 28 milion lines per file. We will use the measurement data of all 24 hours of March 1st. \n",
    "\n",
    "The probe dataset contains a list of 11008 measurement probes used in the RIPE dataset. For each probe they have the ASN (Autonomous System Number) it's connected to.\n",
    "\n",
    "The AS dataset contains a list of 60122 ASNs and the country that they're located in. Combining this with the probe dataset we can find out in which country the probes of the RIPE dataset are located.\n",
    "\n",
    "IP2Location dataset contains IP ranges and assigned countries to them. Using this dataset you can find in which country an IP address is located."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8055e7d",
   "metadata": {},
   "source": [
    "## 1.1 Description of variables used across the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805d6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description of variables used across the entire notebook\n",
    "\n",
    "#AS_df - Complete AS dataset as provided\n",
    "#P_df - Complete probe dataset as provided\n",
    "#EU_list - list of countries in EU\n",
    "#ipv4_df - Complete ip2location dataset\n",
    "    \n",
    "#as_probe_joined_df - Merge of AS and Probe dataset, from 2.1 on filtered to contain only type hosting and location from EU\n",
    "#AS_Probe_RIPE_df - Merge of AS and Probe dataset with probe ids in RIPE dataset and ASNs of type hosting and location from EU\n",
    "#display_df - Same as AS_Probe_RIPE_df with removed duplicate ASNs\n",
    "\n",
    "#RIPE_df - Complete useful contents of a single hour of ripe data (used for 2.1 & 2.2)\n",
    "#RIPE_HostAS_df - Entries of a single hour of ripe data with probe connected to an EU ASN with type host,\n",
    "    #From 2.2 on also filtered to only contain entries with destination address in EU\n",
    "    \n",
    "#Complete_ASN_Set - Set of ASNs of hosting type from EU and in complete RIPE dataset (Ended up being the same for each hour of data)\n",
    "#Complete_RIPE_Entries_df - Complete set of RIPE entries with probe ASN in eu and type host and destination in EU\n",
    "    #Can be loaded from all ripe files\n",
    "    #Also saved in RIPE_00-23.pkl \n",
    "    \n",
    "#ASN_Country_Avg_df - Combination of each country, ASN and average ping\n",
    "#ASN_Country_Matrix_df - Combination of each country, ASN and average ping, with Country as index and ASN as column labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a2c27",
   "metadata": {},
   "source": [
    "## 1.2 Opening the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6bbf1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import bz2\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipaddress\n",
    "import io\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f6047",
   "metadata": {},
   "source": [
    "### AS and Probe datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e615cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AS Dataset\n",
    "\n",
    "AS_Filename = 'data/AS_dataset.pkl'\n",
    "\n",
    "with open(AS_Filename, 'rb') as file:\n",
    "    \n",
    "    AS_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de04b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probe dataset\n",
    "\n",
    "Probe_Filename = 'data/probe_dataset.pkl'\n",
    "\n",
    "with open(Probe_Filename, 'rb') as file:\n",
    "    \n",
    "    P_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10880a8",
   "metadata": {},
   "source": [
    "The AS and Probe dataset can already be merged as we only need the ASNs of the RIPE probes in the probe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8709dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the AS and Probe datasets\n",
    "as_probe_joined_df = pd.merge(P_df,AS_df, on='ASN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531278ed",
   "metadata": {},
   "source": [
    "### EU countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e87af017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU country codes retrieved from: https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:Country_codes\n",
    "# Changed EL -> GR\n",
    "EU_list = ['BE','BG','CZ','DK','DE','EE','IE','GR','ES','FR','HR','IT','CY','LV','LT','LU','HU','MT','NL','AT','PL','PT','RO','SI','SK','FI','SE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f3b4c0",
   "metadata": {},
   "source": [
    "### IP2Location dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6f5e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IP 2 Location dataset\n",
    "\n",
    "IP_Filename = \"data/IP2LOCATION-LITE-DB1.CSV\"\n",
    "\n",
    "ipv4_df = pd.read_csv(IP_Filename)\n",
    "\n",
    "ipv4_df.rename(columns = {'0':'ip_from', '16777215':'ip_to',\n",
    "                              '-':'country_code','-.1':'country_name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41fb6e",
   "metadata": {},
   "source": [
    "### Single ripe file (Used for C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fcd0bffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took: 557.97 seconds\n",
      "Lines added to tuple: 17118054\n"
     ]
    }
   ],
   "source": [
    "#Ripe dataset (Single file)\n",
    "\n",
    "#Option 1 decompressed file\n",
    "decomFilename = 'data/ping-2022-03-01T2300_decom'\n",
    "#decomFile     = open(decomFilename, 'rt')\n",
    "\n",
    "#Option 2 BZ2 file\n",
    "bz2Filename = 'data/ping-2022-03-01T2300.bz2'\n",
    "bz2File     = bz2.open(bz2Filename, 'rt')\n",
    "\n",
    "\n",
    "# List of tuples\n",
    "# https://stackoverflow.com/questions/28056171/how-to-build-and-fill-pandas-dataframe-from-for-loop\n",
    "tuple_list = []\n",
    "\n",
    "start  = time.time()\n",
    "\n",
    "#for line in decomFile:\n",
    "for line in bz2File:\n",
    "    \n",
    "    decoded_line = json.loads(line)\n",
    "    if \"af\" in decoded_line and \"dst_addr\" in decoded_line and \"prb_id\" in decoded_line and \"avg\" in decoded_line: \n",
    "        if (decoded_line[\"af\"] == 4)and (df_dict[\"avg\"] > 0):\n",
    "            tuple_list.append((decoded_line[\"dst_addr\"],decoded_line[\"prb_id\"],decoded_line[\"avg\"]))\n",
    "\n",
    "            \n",
    "dur         = round(time.time() - start,2)\n",
    "print(\"Loading took: \"  + str(dur) + \" seconds\")\n",
    "print(\"Lines added to tuple: \" + str(len(tuple_list)))\n",
    "\n",
    "\n",
    "#finally close bz2File\n",
    "#decomFile.close()\n",
    "bz2File.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dce80df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took: 6.11 seconds\n"
     ]
    }
   ],
   "source": [
    "#Load tuples data into dataframe\n",
    "start  = time.time()\n",
    "\n",
    "RIPE_df = pd.DataFrame(tuple_list)\n",
    "\n",
    "dur         = round(time.time() - start,2)\n",
    "print(\"Loading took: \"  + str(dur) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bd4319",
   "metadata": {},
   "source": [
    "### Complete ripe dataset from BZ2 files\n",
    "Changed reading method to raw characters to save about 20% in loading time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb1dcee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/FoDa Data/ping-2022-03-01T0000.bz2\n",
      "Added 259980 entries and 112 ASNs in 568.8 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T0100.bz2\n",
      "Added 259968 entries and 112 ASNs in 625.48 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T0200.bz2\n",
      "Added 259650 entries and 112 ASNs in 1111.9 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T0300.bz2\n",
      "Added 259786 entries and 113 ASNs in 1177.38 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T0400.bz2\n",
      "Added 259978 entries and 112 ASNs in 1252.62 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T0500.bz2\n",
      "Added 259673 entries and 112 ASNs in 1276.23 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T0600.bz2\n",
      "Added 259513 entries and 112 ASNs in 1280.33 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T0700.bz2\n",
      "Added 259540 entries and 112 ASNs in 1180.1 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T0800.bz2\n",
      "Added 259938 entries and 112 ASNs in 559.47 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T0900.bz2\n",
      "Added 260024 entries and 112 ASNs in 571.24 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T1000.bz2\n",
      "Added 259996 entries and 112 ASNs in 544.0 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T1100.bz2\n",
      "Added 259883 entries and 112 ASNs in 535.67 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T1200.bz2\n",
      "Added 259934 entries and 112 ASNs in 547.46 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T1300.bz2\n",
      "Added 259953 entries and 112 ASNs in 559.34 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T1400.bz2\n",
      "Added 259514 entries and 112 ASNs in 559.75 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T1500.bz2\n",
      "Added 259575 entries and 112 ASNs in 560.78 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T1600.bz2\n",
      "Added 260011 entries and 112 ASNs in 542.26 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T1700.bz2\n",
      "Added 260281 entries and 112 ASNs in 537.14 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T1800.bz2\n",
      "Added 259811 entries and 112 ASNs in 537.99 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T1900.bz2\n",
      "Added 259703 entries and 112 ASNs in 539.43 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T2000.bz2\n",
      "Added 260068 entries and 112 ASNs in 619.41 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T2100.bz2\n",
      "Added 260018 entries and 112 ASNs in 587.5 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T2200.bz2\n",
      "Added 259861 entries and 112 ASNs in 549.94 seconds\n",
      "\n",
      "D:/FoDa Data/ping-2022-03-01T2300.bz2\n",
      "Added 259856 entries and 112 ASNs in 627.44 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RIPE_Filenames = pd.date_range('2022-03-01', periods=24, freq='60min').strftime('D:/FoDa Data/ping-%Y-%m-%dT%H%M.bz2').tolist()\n",
    "\n",
    "Complete_ASN_List = []\n",
    "Complete_RIPE_Entries_df = pd.DataFrame({0:[], 1:[], 2:[], 'Country':[]})\n",
    "\n",
    "# Filter data set for AS's that can be used for hosting in the EU\n",
    "as_probe_joined_df = as_probe_joined_df.loc[(as_probe_joined_df['type'] == 'hosting') & (as_probe_joined_df['Country'].isin(EU_list))]\n",
    "\n",
    "for filename in RIPE_Filenames:\n",
    "    #Read RIPE data\n",
    "    print(filename)\n",
    "    \n",
    "    start  = time.time()\n",
    "    with open(filename, 'rb') as fi:\n",
    "        decomp = bz2.BZ2Decompressor()\n",
    "        residue = b''\n",
    "        total_lines = 0\n",
    "        m = 0\n",
    "        tuple_list = []\n",
    "    \n",
    "        for data in iter(lambda: fi.read(100 * 1024), b''):\n",
    "            raw = residue + decomp.decompress(data) # process the raw data and  concatenate residual of the previous block to the beginning of the current raw data block\n",
    "            residue = b''\n",
    "            # process_data(current_block) => do the processing of the current data block\n",
    "            current_block = raw.split(b'\\n')\n",
    "            if raw[-1] != b'\\n':\n",
    "                residue = current_block.pop() # last line could be incomplete\n",
    "\n",
    "            for items in current_block:\n",
    "                df_dict = json.loads(items.decode('utf-8'))\n",
    "                if ('dst_addr' in df_dict) and (df_dict['af'] == 4) and (df_dict[\"avg\"] > 0):\n",
    "                    tuple_list.append((df_dict[\"dst_addr\"],df_dict[\"prb_id\"],df_dict[\"avg\"]))\n",
    "    \n",
    "    fi.close()\n",
    "    \n",
    "    Temp_RIPE_df = pd.DataFrame(tuple_list)\n",
    "    \n",
    "    #Get list of ASNs\n",
    "    unique_prbID = Temp_RIPE_df[1].unique()\n",
    "    \n",
    "    Temp_AS_Probe_RIPE_df = as_probe_joined_df.loc[as_probe_joined_df['prb_id'].isin(unique_prbID)]\n",
    "    \n",
    "    unique_ASNs = Temp_AS_Probe_RIPE_df['ASN'].unique()\n",
    "    Complete_ASN_List.extend(unique_ASNs)\n",
    "    \n",
    "    \n",
    "    #Get RIPE entries with dst addr in eu\n",
    "    Temp_RIPE_HostAS_df = Temp_RIPE_df.loc[Temp_RIPE_df[1].isin(Temp_AS_Probe_RIPE_df['prb_id'])]\n",
    "    \n",
    "    for i in Temp_RIPE_HostAS_df.index:\n",
    "        Temp_RIPE_HostAS_df.at[i, 0] = int(ipaddress.IPv4Address(Temp_RIPE_HostAS_df[0][i]))\n",
    "\n",
    "    Temp_RIPE_HostAS_df = Temp_RIPE_HostAS_df.sort_values(by=[0])\n",
    "    ipv4_df = ipv4_df.sort_values(by=[\"ip_from\"])\n",
    "\n",
    "    Dest_Addr_Countries = []\n",
    "    ripeindex = 0\n",
    "    ipindex = 0\n",
    "\n",
    "    while Temp_RIPE_HostAS_df.iat[ripeindex, 0] < ipv4_df.at[ipindex, \"ip_from\"]:\n",
    "        ripeindex = ripeindex + 1\n",
    "        Dest_Addr_Countries.append(\"-\")\n",
    "\n",
    "    for ipindex in ipv4_df.index:\n",
    "        while Temp_RIPE_HostAS_df.iat[ripeindex, 0] >= ipv4_df.at[ipindex, \"ip_from\"] and Temp_RIPE_HostAS_df.iat[ripeindex, 0] <= ipv4_df.at[ipindex, \"ip_to\"]:\n",
    "            Dest_Addr_Countries.append(ipv4_df.at[ipindex, \"country_code\"])\n",
    "            ripeindex = ripeindex + 1\n",
    "            if ripeindex >= len(Temp_RIPE_HostAS_df[0]):\n",
    "                break\n",
    "\n",
    "        if ripeindex >= len(Temp_RIPE_HostAS_df[0]):\n",
    "            break\n",
    "            \n",
    "    Temp_RIPE_HostAS_df[\"Country\"] = Dest_Addr_Countries\n",
    "    Temp_RIPE_HostAS_df = Temp_RIPE_HostAS_df.loc[Temp_RIPE_HostAS_df['Country'].isin(EU_list)]    \n",
    "    \n",
    "    \n",
    "    #Add entries to complete dataframe\n",
    "    frames = [Complete_RIPE_Entries_df, Temp_RIPE_HostAS_df]\n",
    "    Complete_RIPE_Entries_df = pd.concat(frames)\n",
    "    \n",
    "    dur         = round(time.time() - start,2)\n",
    "    print(\"Added \" + str(len(Temp_RIPE_HostAS_df[0])) + \" entries and \" + str(len(unique_ASNs)) + \" ASNs in \" + str(dur) + \" seconds\")\n",
    "    print()\n",
    "    \n",
    "\n",
    "#Remove duplicates\n",
    "Complete_ASN_Set = set(Complete_ASN_List)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c5ad89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ASNs: 113\n",
      "Ripe entries: 6236514\n"
     ]
    }
   ],
   "source": [
    "#Save filtered RIPE data to file\n",
    "print(\"Unique ASNs: \" + str(len(Complete_ASN_Set)))\n",
    "print(\"Ripe entries: \" + str(len(Complete_RIPE_Entries_df[0])))\n",
    "\n",
    "Complete_ASN_Set_df = pd.DataFrame(Complete_ASN_Set)\n",
    "\n",
    "Complete_ASN_Set_df.to_pickle(\"data/ASN_00-23.pkl\")\n",
    "\n",
    "Complete_RIPE_Entries_df.to_pickle(\"data/RIPE_00-23.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd74081",
   "metadata": {},
   "source": [
    "### Complete ripe dataset from pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ce4d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probe dataset\n",
    "\n",
    "Ripe_Filename = 'data/RIPE_00-23.pkl'\n",
    "ASN_Filename = 'data/ASN_00-23.pkl'\n",
    "\n",
    "with open(Ripe_Filename, 'rb') as file:\n",
    "    \n",
    "    Complete_RIPE_Entries_df = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open(ASN_Filename, 'rb') as file:\n",
    "    \n",
    "    Complete_ASN_Set_df = pickle.load(file)\n",
    "\n",
    "Complete_ASN_Set = Complete_ASN_Set_df[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b36e9",
   "metadata": {},
   "source": [
    "## 1.2 Limitations in data (Question A)\n",
    "\n",
    "Evaluate if there are limitations in the provided datasets (AS and probe data set). If you find limitations, describe these and conjecture possible reasons, supported with data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ba99a",
   "metadata": {},
   "source": [
    "### 1.2.1 Limitations in the AS and Probe dataset\n",
    "1. The first limitation we could find is that not all probes have an ASN included in the ASN dataset, as shown in the code below. For this reason 303 out of 11008 probes cannot be used for our analysis, because we can't find out where they are located and if they are of type: hosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aefa9ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probe dataset has: 11008 probes\n",
      "However 303 probes have an ASN that is not included in the ASN dataset\n",
      "Excluded probes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prb_id</th>\n",
       "      <th>ASN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>AS1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239</td>\n",
       "      <td>AS8346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>319</td>\n",
       "      <td>AS1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>345</td>\n",
       "      <td>AS1734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>646</td>\n",
       "      <td>AS6067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prb_id     ASN\n",
       "0       2  AS1136\n",
       "1     239  AS8346\n",
       "2     319  AS1909\n",
       "3     345  AS1734\n",
       "4     646  AS6067"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASN_ProbeDataSet = list(P_df['ASN'])\n",
    "ASN_ASNDataSet = list(AS_df['ASN'])\n",
    "\n",
    "temp_tuple = []\n",
    "\n",
    "for index, row in P_df.iterrows():\n",
    "    if row['ASN'] not in ASN_ASNDataSet:\n",
    "        temp_tuple.append((row['prb_id'], row['ASN']))\n",
    "        \n",
    "ExcludedProbes_df = pd.DataFrame(temp_tuple, columns = ['prb_id', 'ASN'])\n",
    "\n",
    "print('The probe dataset has: ' + str(len(P_df)) + ' probes')\n",
    "print('However ' + str(len(ExcludedProbes_df)) + ' probes have an ASN that is not included in the ASN dataset')\n",
    "print('Excluded probes:')\n",
    "ExcludedProbes_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042af47",
   "metadata": {},
   "source": [
    "2. Another possible limitation we have in our datasets is that only 145 out of the 542 possible server locations are analyzed. As shown in the code below there are 542 ASNs inside the EU with type hosting (in the ASN dataset). We can find 339 probes that use these ASNs, however some are connected to the same ASN. This means that we can use data from the 339 probes in the analysis, but we're only analysing 145 different locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e0660ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probes in probe dataset: 11008\n",
      "Probes left after merge with ASN: 10705\n",
      "Useful ASNs in ASN dataset: 542\n",
      "Useful ASNs: 145\n",
      "Useful Probes: 339\n"
     ]
    }
   ],
   "source": [
    "temp_merged_df = pd.merge(P_df,AS_df, on='ASN')\n",
    "temp_merged_df = temp_merged_df.loc[(temp_merged_df['type'] == 'hosting') & (temp_merged_df['Country'].isin(EU_list))]\n",
    "\n",
    "print(\"Probes in probe dataset: \" + str(len(P_df)))\n",
    "print(\"Probes left after merge with ASN: \" + str(len(pd.merge(P_df,AS_df, on='ASN'))))\n",
    "print(\"Useful ASNs in ASN dataset: \" + str(len(AS_df.loc[(AS_df['type'] == 'hosting') & (AS_df['Country'].isin(EU_list))])))\n",
    "print(\"Useful ASNs: \" + str(len(temp_merged_df['ASN'].unique())))\n",
    "print(\"Useful Probes: \" + str(len(temp_merged_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83b1c3",
   "metadata": {},
   "source": [
    "3. After analyzing an hour of the RIPE dataset we found another limitation to the probe dataset. The ripe dataset contains 11608 seperate probe IDs, which is more than the 11008 IDs in the probe dataset. This means we cannot use some entries of the ripe dataset, because we can't check if the probe is in the EU and is of correct type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb80878",
   "metadata": {},
   "source": [
    "### 1.2.2 Limitation in the IP location dataset\n",
    "1. When reading through the RIPE dataset in 2.2 and comparing this to the IP2Location dataset we noticed that the first 79 entries did not fit in the lowest range of the IP2Location dataset. Meaning they have an IP address that is lower than 1.0.0.0 (the lowest IP in the IP2loaction dataset). This is shown in the code at 2.2. The implication is that we cannot check the destination location for these ripe entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ff277",
   "metadata": {},
   "source": [
    "### 1.2.3 Limitations in the RIPE dataset\n",
    "\n",
    "When looking at the RIPE dataset, it was found that for some lines the IP destination addresses were missing. This was not the case for the Probe ID's and average round trip times as these were always included within the lines of the RIPE dataset. Another issue that was found is that some average ping values are -1. A -1 ping time would mean traveling back in time 1 milisecond to deliver a package. We don't think the owners of a ripe probe have invented time travel, so we excluded negative values from the analysis.\n",
    "\n",
    "Below we checked for missing entries and incorrect ping times for the first 5m lines of a RIPE file. Out of the 5 milion line about 11 thousand were missing data and about 870 thousand had incorrect/no ping data. This limits our analysis because the amount of useful data shrinks to about 4/5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb23db7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11428 missing IP destination addresses in the first 5m lines of the RIPE dataset (for one hour)\n",
      "There are 0 missing probe ID's in the first 5m lines of the RIPE dataset (for one hour)\n",
      "There are 0 missing average round-trip time values in the first 5m lines of the RIPE dataset (for one hour)\n",
      "There are 872019 incorrect average round-trip time values in the first 5m lines of the RIPE dataset (for one hour)\n"
     ]
    }
   ],
   "source": [
    "bz2Filename = 'data/ping-2022-03-01T2300.bz2'\n",
    "bz2File_limitation = bz2.open(bz2Filename, 'rt') \n",
    "missing_adres = 0\n",
    "missing_probeID = 0\n",
    "missing_avg = 0\n",
    "incorrect_avg = 0\n",
    "line_number = 0\n",
    "\n",
    "for line in bz2File_limitation:\n",
    "    decoded_line = json.loads(line)\n",
    "    line_number += 1\n",
    "    if \"dst_addr\" not in decoded_line: \n",
    "        missing_adres += 1\n",
    "      \n",
    "    if \"prb_id\" not in decoded_line: \n",
    "        missing_probeID += 1\n",
    "        \n",
    "    if \"avg\" not in decoded_line: \n",
    "        missing_avg += 1\n",
    "    elif decoded_line[\"avg\"] <= 0:\n",
    "        incorrect_avg += 1\n",
    "           \n",
    "    if line_number > 5000000:\n",
    "        print('There are', missing_adres, 'missing IP destination addresses in the first 5m lines of the RIPE dataset (for one hour)')\n",
    "        print('There are', missing_probeID, 'missing probe ID\\'s in the first 5m lines of the RIPE dataset (for one hour)')\n",
    "        print('There are', missing_avg, 'missing average round-trip time values in the first 5m lines of the RIPE dataset (for one hour)')\n",
    "        print('There are', incorrect_avg, 'incorrect average round-trip time values in the first 5m lines of the RIPE dataset (for one hour)')\n",
    "        \n",
    "        break\n",
    "        \n",
    "bz2File_limitation.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9022fe2",
   "metadata": {},
   "source": [
    "# 2 Analysis\n",
    "\n",
    "To find out the best 4 locations for GNI's servers we will first combine the AS, Probe and RIPE dataset to find all the possible hosting locations in the EU. After that we will find all entries in an hour of measurement data from these locations that also have a destination within the EU. Then using the entire dataset we will find all average times from every location to every EU country. To conclude we will select the 4 locations that give the lowest latency to all countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322764a8",
   "metadata": {},
   "source": [
    "## 2.1 AS (Question B)\n",
    "\n",
    "With the AS and probe data set, find the number m of AS’s that can be used for hosting in the EU\n",
    "and have probes in the RIPE data set. Sort the ASN’s in ascending order and include the first and last\n",
    "three in your report (number, name and country).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c0a3800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique probe IDs: 11608\n",
      "Number of probes connected to AS that can be used for hosting in the EU and are in the RIPE dataset: 234\n",
      "Number of AS that can be used for hosting in the EU and are in the RIPE dataset: 113\n"
     ]
    }
   ],
   "source": [
    "#Merge the AS and Probe datasets\n",
    "as_probe_joined_df = pd.merge(P_df,AS_df, on='ASN')\n",
    "\n",
    "# Filter data set for AS's that can be used for hosting in the EU\n",
    "as_probe_joined_df = as_probe_joined_df.loc[(as_probe_joined_df['type'] == 'hosting') & (as_probe_joined_df['Country'].isin(EU_list))]\n",
    "\n",
    "#Get the unique number of probe IDs that are in the RIPE Data\n",
    "unique_prbID = RIPE_df[1].unique()\n",
    "\n",
    "print(\"Unique probe IDs: \" + str(len(unique_prbID)))\n",
    "\n",
    "#Filter the data set by only selecting the ASN's that have probes in the Ripe dataset\n",
    "AS_Probe_RIPE_df = as_probe_joined_df.loc[as_probe_joined_df['prb_id'].isin(unique_prbID)]\n",
    "\n",
    "#Sort by ASN\n",
    "AS_Probe_RIPE_df.sort_values(by=['ASN']).sort_values(by=['ASN'])\n",
    "\n",
    "print(\"Number of probes connected to AS that can be used for hosting in the EU and are in the RIPE dataset: \" + str(len(AS_Probe_RIPE_df[\"ASN\"])))\n",
    "\n",
    "#Remove duplicate ASNs (Probes connected to same AS)\n",
    "display_df = AS_Probe_RIPE_df.drop_duplicates(subset=['ASN'])\n",
    "\n",
    "#Remove unused columns\n",
    "display_df = display_df.drop(columns=['prb_id', 'NumIPs', 'type'])\n",
    "\n",
    "#Sort by ASN\n",
    "display_df.insert(2, 'AS', display_df['ASN'].str.replace('AS', ''))\n",
    "display_df['AS'] = pd.to_numeric(display_df['AS'])\n",
    "display_df = display_df.sort_values('AS')\n",
    "\n",
    "#Print anwser to question B\n",
    "print(\"Number of AS that can be used for hosting in the EU and are in the RIPE dataset: \" + str(len(display_df[\"ASN\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9358d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASN</th>\n",
       "      <th>Country</th>\n",
       "      <th>AS</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6422</th>\n",
       "      <td>AS6724</td>\n",
       "      <td>DE</td>\n",
       "      <td>6724</td>\n",
       "      <td>Strato AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10262</th>\n",
       "      <td>AS8304</td>\n",
       "      <td>FR</td>\n",
       "      <td>8304</td>\n",
       "      <td>Ecritel SARL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8489</th>\n",
       "      <td>AS8315</td>\n",
       "      <td>NL</td>\n",
       "      <td>8315</td>\n",
       "      <td>Sentia Netherlands BV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ASN Country    AS                   Name\n",
       "6422   AS6724      DE  6724              Strato AG\n",
       "10262  AS8304      FR  8304           Ecritel SARL\n",
       "8489   AS8315      NL  8315  Sentia Netherlands BV"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First 3 probes\n",
    "display_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "12469b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASN</th>\n",
       "      <th>Country</th>\n",
       "      <th>AS</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>AS201978</td>\n",
       "      <td>CY</td>\n",
       "      <td>201978</td>\n",
       "      <td>Osbil Technology Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9379</th>\n",
       "      <td>AS203944</td>\n",
       "      <td>LU</td>\n",
       "      <td>203944</td>\n",
       "      <td>NTT Luxembourg PSF S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>AS203953</td>\n",
       "      <td>DK</td>\n",
       "      <td>203953</td>\n",
       "      <td>Hiper A/S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ASN Country      AS                     Name\n",
       "8377  AS201978      CY  201978    Osbil Technology Ltd.\n",
       "9379  AS203944      LU  203944  NTT Luxembourg PSF S.A.\n",
       "2910  AS203953      DK  203953                Hiper A/S"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Last 3 probes\n",
    "display_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edfc66e",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "As described in the limitations of probe and AS dataset: Out of the 11008 probes in the probe dataset, 10705 can be combined with the ASN dataset. 339 Probes in this dataset are of type hosting and in the EU, which use 145 different ASNs.\n",
    "\n",
    "The RIPE dataset contains 11608 probes, 234 of these are in the probe dataset and have an ASN in the EU that can be used for hosting. Some of these probes are connected to the same ASN, leaving 113 ASNs located in the EU that GNI can use for hosting their server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da357dc4",
   "metadata": {},
   "source": [
    "## 2.2 Hosting location (Question C)\n",
    "For a single hour in the RIPE data set: find all valid entries where the probe has hosting type AS and\n",
    "the target IPv4 is from an EU country. Implement this in an efficient way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "145de72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries with probe connected to a potential hosting location: 704517\n"
     ]
    }
   ],
   "source": [
    "#Selects all entries in RIPE data with probe connected to EU as of type hosting\n",
    "RIPE_HostAS_df = RIPE_df.loc[RIPE_df[1].isin(AS_Probe_RIPE_df['prb_id'])]\n",
    "\n",
    "print(\"Entries with probe connected to a potential hosting location: \" + str(len(RIPE_HostAS_df[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d3e27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert IP strings to IP integers\n",
    "for i in RIPE_HostAS_df.index:  \n",
    "    IP_Splitstring = RIPE_HostAS_df[0][i].split(\".\") \n",
    "    RIPE_HostAS_df.at[i, 0] = int(IP_Splitstring[0]) * 16581375 + int(IP_Splitstring[1]) * 65025 + int(IP_Splitstring[2]) * 255 + int(IP_Splitstring[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf7e0d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP addresses not included in IP2location dataset: 79\n",
      "IP addresses linked to country: 704517\n"
     ]
    }
   ],
   "source": [
    "#Add country of dst_addr to RIPE_HostAS_df\n",
    "\n",
    "#Sorting the IP lists so we can check from low to high IPs\n",
    "RIPE_HostAS_df = RIPE_HostAS_df.sort_values(by=[0])\n",
    "ipv4_df = ipv4_df.sort_values(by=[\"ip_from\"])\n",
    "\n",
    "Dest_Addr_Countries = []\n",
    "ripeindex = 0\n",
    "ipindex = 0\n",
    "\n",
    "#Check if there are IP addresses lower than included in the IP2Location dataset\n",
    "while RIPE_HostAS_df.iat[ripeindex, 0] < ipv4_df.at[ipindex, \"ip_from\"]:\n",
    "    ripeindex = ripeindex + 1\n",
    "    Dest_Addr_Countries.append(\"-\")\n",
    "\n",
    "print(\"IP addresses not included in IP2location dataset: \" + str(ripeindex))\n",
    "\n",
    "#Check for each range of IP addresses in the IP2Location dataset which dst_addr IPs are present\n",
    "#Break loop early if the length of the RIPE dataset is reached\n",
    "for ipindex in ipv4_df.index:\n",
    "    while RIPE_HostAS_df.iat[ripeindex, 0] >= ipv4_df.at[ipindex, \"ip_from\"] and RIPE_HostAS_df.iat[ripeindex, 0] <= ipv4_df.at[ipindex, \"ip_to\"]:\n",
    "        Dest_Addr_Countries.append(ipv4_df.at[ipindex, \"country_code\"])\n",
    "        ripeindex = ripeindex + 1\n",
    "        if ripeindex >= len(RIPE_HostAS_df[0]):\n",
    "            break\n",
    "    \n",
    "    if ripeindex >= len(RIPE_HostAS_df[0]):\n",
    "        break\n",
    "\n",
    "print(\"IP addresses linked to country: \" + str(len(Dest_Addr_Countries)))\n",
    "\n",
    "#Add list for destination address location to dataframe\n",
    "RIPE_HostAS_df[\"Country\"] = Dest_Addr_Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "163f6d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries with probe connected to an EU AS with type hosting and destination address within EU: 134528\n"
     ]
    }
   ],
   "source": [
    "#Remove entries not in EU\n",
    "RIPE_HostAS_df = RIPE_HostAS_df.loc[RIPE_HostAS_df['Country'].isin(EU_list)]\n",
    "\n",
    "print(\"Entries with probe connected to an EU AS with type hosting and destination address within EU: \" + str(len(RIPE_HostAS_df[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1759191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2202050</th>\n",
       "      <td>34230351</td>\n",
       "      <td>6413</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7105316</th>\n",
       "      <td>34230366</td>\n",
       "      <td>6332</td>\n",
       "      <td>3.692374</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10643681</th>\n",
       "      <td>34322379</td>\n",
       "      <td>18820</td>\n",
       "      <td>3.350143</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6852126</th>\n",
       "      <td>34322379</td>\n",
       "      <td>19338</td>\n",
       "      <td>4.226577</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003356</th>\n",
       "      <td>34322379</td>\n",
       "      <td>52596</td>\n",
       "      <td>1.965267</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0      1         2 Country\n",
       "2202050   34230351   6413  0.642325      FR\n",
       "7105316   34230366   6332  3.692374      FR\n",
       "10643681  34322379  18820  3.350143      FR\n",
       "6852126   34322379  19338  4.226577      FR\n",
       "6003356   34322379  52596  1.965267      FR"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RIPE_HostAS_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39ee97",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Filtering through an hour of the ripe dataset, we found 704517 out of 17118054 entries that have a probe connected to a potential hosting location. 79 of these had an unusable IP adress and were excluded as described in chapter 1.2.2. 134528 entries also had a destination address in the EU. Meaning for an hour of data we have 134528 measurements of potential hosting locations to potential client locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404e5a2",
   "metadata": {},
   "source": [
    "## 2.3 Latency (Question D)\n",
    "Move from using only an hour to the full day. It is advisable to store the raw results of each file. Then,\n",
    "using all processed files, calculate the average latency’s for each country-AS combination and store\n",
    "the results into one ncountries ×m matrix. If we could place one server in each country, what would the\n",
    "minimum average latency be for each country? (include in your report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "81410553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took: 61.24 seconds\n"
     ]
    }
   ],
   "source": [
    "#Load the avg ping for each country-AS combination into a DF\n",
    "ASN_Country_Avg =[]\n",
    "start  = time.time()\n",
    "\n",
    "for country in EU_list:\n",
    "    \n",
    "    #Filter each country's ping values seperately into a dataframe\n",
    "    country_df = Complete_RIPE_Entries_df.loc[Complete_RIPE_Entries_df['Country'] == country]\n",
    "    \n",
    "    for ASN in Complete_ASN_Set:\n",
    "        \n",
    "        #Filter probe IDs for each seperate ASN\n",
    "        #There are more probes than ASs to calculate the average ping more accurately we use all probes\n",
    "        prb_df = as_probe_joined_df.loc[as_probe_joined_df['ASN'] == ASN]                            \n",
    "        \n",
    "        #Filter the ping data so it includes all probes from selected ASN and selected country\n",
    "        temp_df = country_df.loc[country_df[1].isin(prb_df['prb_id'])]\n",
    "        \n",
    "        #Create sum of all ASN - Country ping measurements\n",
    "        sumvalue = 0\n",
    "        i = 0\n",
    "        for pingvalue in temp_df[2]:\n",
    "            sumvalue = sumvalue + pingvalue\n",
    "            i = i+1\n",
    "        \n",
    "        #Check if there are ping measurements between AS - Country\n",
    "        #Calculate average when needed, enter nan when no data available\n",
    "        if not i == 0:\n",
    "            average = sumvalue/i\n",
    "            ASN_Country_Avg.append((country, ASN, average))\n",
    "        else:\n",
    "            ASN_Country_Avg.append((country, ASN, np.nan))\n",
    "            \n",
    "    \n",
    "\n",
    "#Load tuple list into dataframe\n",
    "ASN_Country_Avg_df = pd.DataFrame(ASN_Country_Avg)  \n",
    "ASN_Country_Avg_df.columns = ['Country','ASN','Average latency']\n",
    "\n",
    "dur         = round(time.time() - start,2)\n",
    "print(\"Loading took: \" + str(dur) + \" seconds\")\n",
    "\n",
    "#ASN_Country_Avg_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f5c390a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AS12676</th>\n",
       "      <th>AS12824</th>\n",
       "      <th>AS12859</th>\n",
       "      <th>AS12876</th>\n",
       "      <th>AS12993</th>\n",
       "      <th>AS13287</th>\n",
       "      <th>AS15401</th>\n",
       "      <th>AS15598</th>\n",
       "      <th>AS15685</th>\n",
       "      <th>AS15817</th>\n",
       "      <th>...</th>\n",
       "      <th>AS61211</th>\n",
       "      <th>AS62000</th>\n",
       "      <th>AS62282</th>\n",
       "      <th>AS62416</th>\n",
       "      <th>AS6724</th>\n",
       "      <th>AS8304</th>\n",
       "      <th>AS8315</th>\n",
       "      <th>AS8560</th>\n",
       "      <th>AS8893</th>\n",
       "      <th>AS9211</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BE</th>\n",
       "      <td>11.166851</td>\n",
       "      <td>40.074876</td>\n",
       "      <td>10.507757</td>\n",
       "      <td>15.188454</td>\n",
       "      <td>47.158572</td>\n",
       "      <td>50.331953</td>\n",
       "      <td>32.000726</td>\n",
       "      <td>14.272470</td>\n",
       "      <td>7.090369</td>\n",
       "      <td>17.918840</td>\n",
       "      <td>...</td>\n",
       "      <td>13.677713</td>\n",
       "      <td>9.139959</td>\n",
       "      <td>30.264256</td>\n",
       "      <td>37.625758</td>\n",
       "      <td>21.895923</td>\n",
       "      <td>36.613629</td>\n",
       "      <td>14.180203</td>\n",
       "      <td>15.608819</td>\n",
       "      <td>14.248650</td>\n",
       "      <td>23.182450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>34.065354</td>\n",
       "      <td>56.240200</td>\n",
       "      <td>37.460264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.493638</td>\n",
       "      <td>37.480807</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.181894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.739097</td>\n",
       "      <td>45.362127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.467327</td>\n",
       "      <td>39.602015</td>\n",
       "      <td>34.999751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CZ</th>\n",
       "      <td>12.093469</td>\n",
       "      <td>37.812455</td>\n",
       "      <td>25.809037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.435987</td>\n",
       "      <td>16.390667</td>\n",
       "      <td>...</td>\n",
       "      <td>26.435202</td>\n",
       "      <td>19.131593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.626967</td>\n",
       "      <td>19.849781</td>\n",
       "      <td>37.179526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.805042</td>\n",
       "      <td>17.589719</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DK</th>\n",
       "      <td>20.984928</td>\n",
       "      <td>30.216756</td>\n",
       "      <td>16.241454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.615563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.766526</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.615565</td>\n",
       "      <td>27.155439</td>\n",
       "      <td>54.632706</td>\n",
       "      <td>21.405880</td>\n",
       "      <td>40.281921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.094678</td>\n",
       "      <td>17.782914</td>\n",
       "      <td>17.562175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>8.990465</td>\n",
       "      <td>26.565322</td>\n",
       "      <td>16.135886</td>\n",
       "      <td>15.900784</td>\n",
       "      <td>33.302987</td>\n",
       "      <td>39.107490</td>\n",
       "      <td>34.125600</td>\n",
       "      <td>6.982521</td>\n",
       "      <td>12.363413</td>\n",
       "      <td>13.329492</td>\n",
       "      <td>...</td>\n",
       "      <td>30.209470</td>\n",
       "      <td>17.422402</td>\n",
       "      <td>28.505335</td>\n",
       "      <td>46.415247</td>\n",
       "      <td>17.954170</td>\n",
       "      <td>32.618335</td>\n",
       "      <td>12.573617</td>\n",
       "      <td>9.873529</td>\n",
       "      <td>12.003693</td>\n",
       "      <td>11.463877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE</th>\n",
       "      <td>33.675421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.198870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.687826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.387413</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.549688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.265312</td>\n",
       "      <td>30.381828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.153123</td>\n",
       "      <td>30.205509</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IE</th>\n",
       "      <td>23.375734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.699692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.080462</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.829812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.472121</td>\n",
       "      <td>31.682828</td>\n",
       "      <td>37.142185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.672747</td>\n",
       "      <td>25.116084</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GR</th>\n",
       "      <td>45.387253</td>\n",
       "      <td>67.395819</td>\n",
       "      <td>57.466218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.755894</td>\n",
       "      <td>48.657652</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.527981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.508062</td>\n",
       "      <td>52.276134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.504839</td>\n",
       "      <td>52.042627</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>36.942678</td>\n",
       "      <td>54.136859</td>\n",
       "      <td>40.268548</td>\n",
       "      <td>19.919217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.318842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.671675</td>\n",
       "      <td>38.207938</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.958473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.476205</td>\n",
       "      <td>43.597386</td>\n",
       "      <td>33.196142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.745641</td>\n",
       "      <td>38.570608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>17.599229</td>\n",
       "      <td>38.852481</td>\n",
       "      <td>21.875865</td>\n",
       "      <td>7.830189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.534623</td>\n",
       "      <td>10.814385</td>\n",
       "      <td>22.820869</td>\n",
       "      <td>16.248210</td>\n",
       "      <td>22.054226</td>\n",
       "      <td>...</td>\n",
       "      <td>43.471482</td>\n",
       "      <td>7.703143</td>\n",
       "      <td>35.566478</td>\n",
       "      <td>36.405002</td>\n",
       "      <td>27.983363</td>\n",
       "      <td>19.763384</td>\n",
       "      <td>28.061133</td>\n",
       "      <td>16.793594</td>\n",
       "      <td>21.933111</td>\n",
       "      <td>21.031365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>27.303667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.938949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.136472</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.715872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.067052</td>\n",
       "      <td>30.321585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.677648</td>\n",
       "      <td>30.527161</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>22.870489</td>\n",
       "      <td>48.510649</td>\n",
       "      <td>30.376578</td>\n",
       "      <td>22.525187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.059027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.168855</td>\n",
       "      <td>27.066700</td>\n",
       "      <td>...</td>\n",
       "      <td>33.710254</td>\n",
       "      <td>23.781522</td>\n",
       "      <td>35.588621</td>\n",
       "      <td>48.395509</td>\n",
       "      <td>33.836672</td>\n",
       "      <td>34.063527</td>\n",
       "      <td>45.841982</td>\n",
       "      <td>21.240570</td>\n",
       "      <td>26.108201</td>\n",
       "      <td>28.181888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LV</th>\n",
       "      <td>32.742404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.317133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.787425</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.873033</td>\n",
       "      <td>6.193064</td>\n",
       "      <td>69.735524</td>\n",
       "      <td>23.758921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.492840</td>\n",
       "      <td>28.793589</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT</th>\n",
       "      <td>29.556071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.894807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.185846</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.691008</td>\n",
       "      <td>1.022234</td>\n",
       "      <td>62.377509</td>\n",
       "      <td>24.526096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.968171</td>\n",
       "      <td>29.850341</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU</th>\n",
       "      <td>9.230467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.451388</td>\n",
       "      <td>19.345321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.571945</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.780888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.738941</td>\n",
       "      <td>20.239944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.376000</td>\n",
       "      <td>13.158385</td>\n",
       "      <td>30.390710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HU</th>\n",
       "      <td>22.019600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.771274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.492204</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.484590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.544043</td>\n",
       "      <td>22.098969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.052384</td>\n",
       "      <td>25.433766</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL</th>\n",
       "      <td>10.654300</td>\n",
       "      <td>32.972481</td>\n",
       "      <td>4.799654</td>\n",
       "      <td>15.046451</td>\n",
       "      <td>28.766117</td>\n",
       "      <td>29.916225</td>\n",
       "      <td>32.813123</td>\n",
       "      <td>12.288465</td>\n",
       "      <td>13.162906</td>\n",
       "      <td>14.780841</td>\n",
       "      <td>...</td>\n",
       "      <td>27.676840</td>\n",
       "      <td>17.000521</td>\n",
       "      <td>25.121527</td>\n",
       "      <td>43.282719</td>\n",
       "      <td>15.453117</td>\n",
       "      <td>27.345879</td>\n",
       "      <td>2.928960</td>\n",
       "      <td>15.010066</td>\n",
       "      <td>13.435868</td>\n",
       "      <td>11.478944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>17.563579</td>\n",
       "      <td>17.648889</td>\n",
       "      <td>20.625767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.010137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.627563</td>\n",
       "      <td>13.972880</td>\n",
       "      <td>20.629958</td>\n",
       "      <td>...</td>\n",
       "      <td>21.040824</td>\n",
       "      <td>24.677251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.791121</td>\n",
       "      <td>23.426125</td>\n",
       "      <td>33.990846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.833696</td>\n",
       "      <td>20.263268</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL</th>\n",
       "      <td>23.853206</td>\n",
       "      <td>11.742513</td>\n",
       "      <td>24.563244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.099691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.269506</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.784926</td>\n",
       "      <td>8.388135</td>\n",
       "      <td>62.535057</td>\n",
       "      <td>24.704146</td>\n",
       "      <td>50.855610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.765634</td>\n",
       "      <td>22.760180</td>\n",
       "      <td>15.355375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>41.993323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.607150</td>\n",
       "      <td>28.107272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.765233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.555562</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.167093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.022465</td>\n",
       "      <td>51.823025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.024771</td>\n",
       "      <td>47.437607</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>31.659716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.673875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.508196</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.076013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.718602</td>\n",
       "      <td>37.802199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.987513</td>\n",
       "      <td>35.003576</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>25.296005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.878451</td>\n",
       "      <td>35.574921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.311899</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.889465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.275240</td>\n",
       "      <td>36.704934</td>\n",
       "      <td>51.765596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.311056</td>\n",
       "      <td>28.305851</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK</th>\n",
       "      <td>NaN</td>\n",
       "      <td>55.872259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FI</th>\n",
       "      <td>31.618490</td>\n",
       "      <td>57.193475</td>\n",
       "      <td>30.548735</td>\n",
       "      <td>51.345363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.037844</td>\n",
       "      <td>...</td>\n",
       "      <td>52.772197</td>\n",
       "      <td>39.027469</td>\n",
       "      <td>13.230119</td>\n",
       "      <td>68.962465</td>\n",
       "      <td>33.592323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.239730</td>\n",
       "      <td>26.369765</td>\n",
       "      <td>30.536567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>23.382599</td>\n",
       "      <td>30.615330</td>\n",
       "      <td>19.935498</td>\n",
       "      <td>28.591996</td>\n",
       "      <td>14.819589</td>\n",
       "      <td>34.845372</td>\n",
       "      <td>30.573320</td>\n",
       "      <td>8.162778</td>\n",
       "      <td>16.174253</td>\n",
       "      <td>26.019051</td>\n",
       "      <td>...</td>\n",
       "      <td>14.358897</td>\n",
       "      <td>30.582977</td>\n",
       "      <td>6.204618</td>\n",
       "      <td>58.820538</td>\n",
       "      <td>33.821510</td>\n",
       "      <td>133.731289</td>\n",
       "      <td>9.809138</td>\n",
       "      <td>23.972091</td>\n",
       "      <td>18.890303</td>\n",
       "      <td>10.051866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AS12676    AS12824    AS12859    AS12876    AS12993    AS13287  \\\n",
       "Country                                                                     \n",
       "BE       11.166851  40.074876  10.507757  15.188454  47.158572  50.331953   \n",
       "BG       34.065354  56.240200  37.460264        NaN        NaN        NaN   \n",
       "CZ       12.093469  37.812455  25.809037        NaN        NaN        NaN   \n",
       "DK       20.984928  30.216756  16.241454        NaN  34.615563        NaN   \n",
       "DE        8.990465  26.565322  16.135886  15.900784  33.302987  39.107490   \n",
       "EE       33.675421        NaN  37.198870        NaN   9.687826        NaN   \n",
       "IE       23.375734        NaN  25.699692        NaN        NaN        NaN   \n",
       "GR       45.387253  67.395819  57.466218        NaN        NaN        NaN   \n",
       "ES       36.942678  54.136859  40.268548  19.919217        NaN  16.318842   \n",
       "FR       17.599229  38.852481  21.875865   7.830189        NaN  27.534623   \n",
       "HR       27.303667        NaN  46.938949        NaN        NaN        NaN   \n",
       "IT       22.870489  48.510649  30.376578  22.525187        NaN  30.059027   \n",
       "CY             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "LV       32.742404        NaN  31.317133        NaN   0.878124        NaN   \n",
       "LT       29.556071        NaN  33.894807        NaN        NaN        NaN   \n",
       "LU        9.230467        NaN  13.451388  19.345321        NaN        NaN   \n",
       "HU       22.019600        NaN  29.771274        NaN        NaN        NaN   \n",
       "MT             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "NL       10.654300  32.972481   4.799654  15.046451  28.766117  29.916225   \n",
       "AT       17.563579  17.648889  20.625767        NaN  35.010137        NaN   \n",
       "PL       23.853206  11.742513  24.563244        NaN  23.099691        NaN   \n",
       "PT       41.993323        NaN  45.607150  28.107272        NaN  21.765233   \n",
       "RO       31.659716        NaN  37.673875        NaN        NaN        NaN   \n",
       "SI       25.296005        NaN  37.878451  35.574921        NaN        NaN   \n",
       "SK             NaN  55.872259        NaN        NaN        NaN        NaN   \n",
       "FI       31.618490  57.193475  30.548735  51.345363        NaN        NaN   \n",
       "SE       23.382599  30.615330  19.935498  28.591996  14.819589  34.845372   \n",
       "\n",
       "           AS15401    AS15598    AS15685    AS15817  ...    AS61211  \\\n",
       "Country                                              ...              \n",
       "BE       32.000726  14.272470   7.090369  17.918840  ...  13.677713   \n",
       "BG             NaN        NaN  24.493638  37.480807  ...        NaN   \n",
       "CZ             NaN        NaN   2.435987  16.390667  ...  26.435202   \n",
       "DK             NaN        NaN        NaN  22.766526  ...        NaN   \n",
       "DE       34.125600   6.982521  12.363413  13.329492  ...  30.209470   \n",
       "EE             NaN        NaN        NaN  37.387413  ...        NaN   \n",
       "IE             NaN        NaN        NaN  29.080462  ...        NaN   \n",
       "GR             NaN        NaN  36.755894  48.657652  ...        NaN   \n",
       "ES             NaN        NaN  58.671675  38.207938  ...        NaN   \n",
       "FR       10.814385  22.820869  16.248210  22.054226  ...  43.471482   \n",
       "HR             NaN        NaN        NaN  27.136472  ...        NaN   \n",
       "IT             NaN        NaN  19.168855  27.066700  ...  33.710254   \n",
       "CY             NaN        NaN        NaN        NaN  ...        NaN   \n",
       "LV             NaN        NaN        NaN  33.787425  ...        NaN   \n",
       "LT             NaN        NaN        NaN  34.185846  ...        NaN   \n",
       "LU             NaN        NaN        NaN  13.571945  ...        NaN   \n",
       "HU             NaN        NaN        NaN  25.492204  ...        NaN   \n",
       "MT             NaN        NaN        NaN        NaN  ...        NaN   \n",
       "NL       32.813123  12.288465  13.162906  14.780841  ...  27.676840   \n",
       "AT             NaN  10.627563  13.972880  20.629958  ...  21.040824   \n",
       "PL             NaN        NaN        NaN  26.269506  ...        NaN   \n",
       "PT             NaN        NaN        NaN  44.555562  ...        NaN   \n",
       "RO             NaN        NaN        NaN  33.508196  ...        NaN   \n",
       "SI             NaN        NaN        NaN  27.311899  ...        NaN   \n",
       "SK             NaN        NaN        NaN        NaN  ...        NaN   \n",
       "FI             NaN        NaN        NaN  32.037844  ...  52.772197   \n",
       "SE       30.573320   8.162778  16.174253  26.019051  ...  14.358897   \n",
       "\n",
       "           AS62000    AS62282    AS62416     AS6724      AS8304     AS8315  \\\n",
       "Country                                                                      \n",
       "BE        9.139959  30.264256  37.625758  21.895923   36.613629  14.180203   \n",
       "BG       37.181894        NaN  65.739097  45.362127         NaN        NaN   \n",
       "CZ       19.131593        NaN  55.626967  19.849781   37.179526        NaN   \n",
       "DK       31.615565  27.155439  54.632706  21.405880   40.281921        NaN   \n",
       "DE       17.422402  28.505335  46.415247  17.954170   32.618335  12.573617   \n",
       "EE       41.549688        NaN  70.265312  30.381828         NaN        NaN   \n",
       "IE       23.829812        NaN  46.472121  31.682828   37.142185        NaN   \n",
       "GR       51.527981        NaN  77.508062  52.276134         NaN        NaN   \n",
       "ES       29.958473        NaN  19.476205  43.597386   33.196142        NaN   \n",
       "FR        7.703143  35.566478  36.405002  27.983363   19.763384  28.061133   \n",
       "HR       30.715872        NaN  61.067052  30.321585         NaN        NaN   \n",
       "IT       23.781522  35.588621  48.395509  33.836672   34.063527  45.841982   \n",
       "CY             NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "LV       37.873033   6.193064  69.735524  23.758921         NaN        NaN   \n",
       "LT       35.691008   1.022234  62.377509  24.526096         NaN        NaN   \n",
       "LU        9.780888        NaN  44.738941  20.239944         NaN        NaN   \n",
       "HU       28.484590        NaN  64.544043  22.098969         NaN        NaN   \n",
       "MT             NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "NL       17.000521  25.121527  43.282719  15.453117   27.345879   2.928960   \n",
       "AT       24.677251        NaN  52.791121  23.426125   33.990846        NaN   \n",
       "PL       47.784926   8.388135  62.535057  24.704146   50.855610        NaN   \n",
       "PT       34.167093        NaN   1.022465  51.823025         NaN        NaN   \n",
       "RO       39.076013        NaN  67.718602  37.802199         NaN        NaN   \n",
       "SI       30.889465        NaN  58.275240  36.704934   51.765596        NaN   \n",
       "SK             NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "FI       39.027469  13.230119  68.962465  33.592323         NaN        NaN   \n",
       "SE       30.582977   6.204618  58.820538  33.821510  133.731289   9.809138   \n",
       "\n",
       "            AS8560     AS8893     AS9211  \n",
       "Country                                   \n",
       "BE       15.608819  14.248650  23.182450  \n",
       "BG       31.467327  39.602015  34.999751  \n",
       "CZ       11.805042  17.589719        NaN  \n",
       "DK       22.094678  17.782914  17.562175  \n",
       "DE        9.873529  12.003693  11.463877  \n",
       "EE       35.153123  30.205509        NaN  \n",
       "IE       25.672747  25.116084        NaN  \n",
       "GR       44.504839  52.042627        NaN  \n",
       "ES       33.745641  38.570608        NaN  \n",
       "FR       16.793594  21.933111  21.031365  \n",
       "HR       22.677648  30.527161        NaN  \n",
       "IT       21.240570  26.108201  28.181888  \n",
       "CY             NaN        NaN        NaN  \n",
       "LV       30.492840  28.793589        NaN  \n",
       "LT       28.968171  29.850341        NaN  \n",
       "LU        7.376000  13.158385  30.390710  \n",
       "HU       19.052384  25.433766        NaN  \n",
       "MT             NaN        NaN        NaN  \n",
       "NL       15.010066  13.435868  11.478944  \n",
       "AT       16.833696  20.263268        NaN  \n",
       "PL       21.765634  22.760180  15.355375  \n",
       "PT       41.024771  47.437607        NaN  \n",
       "RO       29.987513  35.003576        NaN  \n",
       "SI       32.311056  28.305851        NaN  \n",
       "SK             NaN        NaN        NaN  \n",
       "FI       30.239730  26.369765  30.536567  \n",
       "SE       23.972091  18.890303  10.051866  \n",
       "\n",
       "[27 rows x 113 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display Country-AS-AVerage dataframe as a matrix\n",
    "\n",
    "ASN_Country_Avg_df = ASN_Country_Avg_df.iloc[:, 1:] # asn and latency\n",
    "df_groupby = ASN_Country_Avg_df.groupby('ASN')['Average latency'].apply(list)\n",
    "\n",
    "new_dftesttest = np.zeros((len(df_groupby), len(df_groupby[0])))\n",
    "for i in range(len(df_groupby)):\n",
    "    for j in range(len(df_groupby[0])):\n",
    "        new_dftesttest[i,j] = df_groupby[i][j]\n",
    "\n",
    "df_groupby.index\n",
    "ASN_Country_Matrix_df = pd.DataFrame(new_dftesttest.transpose())   \n",
    "\n",
    "column_list = list(df_groupby.index)\n",
    "ASN_Country_Matrix_df.columns=column_list\n",
    "ASN_Country_Matrix_df.insert(0,'Country', EU_list)\n",
    "ASN_Country_Matrix_df.set_index('Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9435a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kooltje\\AppData\\Local\\Temp\\ipykernel_2628\\1058702649.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  min_latency_s = ASN_Country_Matrix_df.min(axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min Latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BE</th>\n",
       "      <td>2.871515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>8.684864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CZ</th>\n",
       "      <td>1.802406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DK</th>\n",
       "      <td>2.938525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>6.982521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE</th>\n",
       "      <td>1.791287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IE</th>\n",
       "      <td>3.860732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GR</th>\n",
       "      <td>31.803821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>5.093963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>2.770778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>14.494660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>0.939225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CY</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LV</th>\n",
       "      <td>0.878124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT</th>\n",
       "      <td>1.022234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU</th>\n",
       "      <td>4.902144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HU</th>\n",
       "      <td>3.345774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL</th>\n",
       "      <td>1.557510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>7.425945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL</th>\n",
       "      <td>6.064111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>0.832088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>5.569470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>10.938901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK</th>\n",
       "      <td>5.854201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FI</th>\n",
       "      <td>7.938413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>0.933680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min Latency\n",
       "BE     2.871515\n",
       "BG     8.684864\n",
       "CZ     1.802406\n",
       "DK     2.938525\n",
       "DE     6.982521\n",
       "EE     1.791287\n",
       "IE     3.860732\n",
       "GR    31.803821\n",
       "ES     5.093963\n",
       "FR     2.770778\n",
       "HR    14.494660\n",
       "IT     0.939225\n",
       "CY          NaN\n",
       "LV     0.878124\n",
       "LT     1.022234\n",
       "LU     4.902144\n",
       "HU     3.345774\n",
       "MT          NaN\n",
       "NL     1.557510\n",
       "AT     7.425945\n",
       "PL     6.064111\n",
       "PT     0.832088\n",
       "RO     5.569470\n",
       "SI    10.938901\n",
       "SK     5.854201\n",
       "FI     7.938413\n",
       "SE     0.933680"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the minimum latency for each country\n",
    "min_latency_s = ASN_Country_Matrix_df.min(axis = 1)\n",
    "min_latency_df = pd.Series.to_frame(min_latency_s, 'min Latency')\n",
    "min_latency_df.index = EU_list\n",
    "min_latency_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad08df5",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "After checking calculating the average latency of each potential hosting location to each eu country we visualized this in a matrix. Some country-as combination do not have data. This is likely because not every measurement probe will send a ping request to a location within every EU country. \n",
    "\n",
    "We calculated the minimum average latency from a measurement probe to every EU country. If we could place a 26 servers, one for each country, this is the average latency each country could expect. We did notice some flaws in our results: \n",
    "- There are no measurements available to both Cyprus and Malta. \n",
    "- Some countries have a relatively high ping (Greece, and Hungary). There likely isn't a measurement probe in the RIPE dataset in or near these countries, so a hosting location near these places is probably not considered in our analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30bbaa0",
   "metadata": {},
   "source": [
    "## 2.4 Optimal server locations (Question E)\n",
    "Since we are only allowed to place four servers, determine the best four datacenters based on the total\n",
    "latency for all countries. Report your findings and your procedure to obtain them. Also include the\n",
    "average latency for each country.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "15eeba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took: 3475.63 seconds\n",
      "Set of ASNs with the lowest average latency to all countries: ('AS34971', 'AS16245', 'AS25151', 'AS15598')\n",
      "Average latency from this set: 6.7286224930603\n"
     ]
    }
   ],
   "source": [
    "#Find optimal location of 4 servers\n",
    "\n",
    "i = 0\n",
    "start  = time.time()\n",
    "Set_Average = 1000\n",
    "\n",
    "#Find each possible combination of 4 ASNs in ASN set\n",
    "ASNCombinations = [ASNCombination for ASNCombination in combinations(Complete_ASN_Set,4)]  \n",
    "\n",
    "for ASNCombination in ASNCombinations:  \n",
    "    #Calculate the minimum latency for each country in this ASN set\n",
    "    combination_df  = ASN_Country_Matrix_df[[ASNCombination[0], ASNCombination[1], ASNCombination[2], ASNCombination[3]]]\n",
    "    #Calculate average latency of minimum latency of each country in this set\n",
    "    min_latency_s = combination_df.min(axis = 1)\n",
    "    \n",
    "    #Save the lowest average latency of all sets\n",
    "    if Set_Average > min_latency_s.mean():    \n",
    "        Set_Average = min_latency_s.mean()\n",
    "        CombinationIndex = i\n",
    "    \n",
    "    i = i+1\n",
    "    #if i > 10000:\n",
    "    #    break\n",
    "        \n",
    "        \n",
    "\n",
    "dur         = round(time.time() - start,2)\n",
    "expecteddur = round(dur * len(ASNCombinations)/i)\n",
    "print(\"Loading took: \" + str(dur) + \" seconds\")\n",
    "#print(\"Expected time: \" + str(expecteddur) + \" seconds\")\n",
    "print(\"Set of ASNs with the lowest average latency to all countries: \" + str(ASNCombinations[CombinationIndex]))\n",
    "print(\"Average latency from this set: \" + str(Set_Average))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f16810b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASN</th>\n",
       "      <th>Country</th>\n",
       "      <th>Name</th>\n",
       "      <th>NumIPs</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15365</th>\n",
       "      <td>AS16245</td>\n",
       "      <td>DK</td>\n",
       "      <td>Netgroup A/S</td>\n",
       "      <td>68,608</td>\n",
       "      <td>hosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18721</th>\n",
       "      <td>AS15598</td>\n",
       "      <td>DE</td>\n",
       "      <td>QSC AG</td>\n",
       "      <td>165,376</td>\n",
       "      <td>hosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28851</th>\n",
       "      <td>AS34971</td>\n",
       "      <td>IT</td>\n",
       "      <td>Prometeus di Daniela Agro</td>\n",
       "      <td>11,008</td>\n",
       "      <td>hosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34778</th>\n",
       "      <td>AS25151</td>\n",
       "      <td>NL</td>\n",
       "      <td>Cyso Management B.V.</td>\n",
       "      <td>16,640</td>\n",
       "      <td>hosting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ASN Country                       Name   NumIPs     type\n",
       "15365  AS16245      DK               Netgroup A/S   68,608  hosting\n",
       "18721  AS15598      DE                     QSC AG  165,376  hosting\n",
       "28851  AS34971      IT  Prometeus di Daniela Agro   11,008  hosting\n",
       "34778  AS25151      NL       Cyso Management B.V.   16,640  hosting"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get name, country and number of available IPs of selected ASNs\n",
    "AS_Optimal_df = AS_df[AS_df['ASN'].isin(ASNCombinations[CombinationIndex])]\n",
    "\n",
    "AS_Optimal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b369265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a099066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kooltje\\AppData\\Local\\Temp\\ipykernel_2628\\3103259338.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  min_latency_s = ASN_Country_Matrix_df.min(axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min Latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BE</th>\n",
       "      <td>2.871515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>8.684864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CZ</th>\n",
       "      <td>1.802406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DK</th>\n",
       "      <td>2.938525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>6.982521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE</th>\n",
       "      <td>1.791287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IE</th>\n",
       "      <td>3.860732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GR</th>\n",
       "      <td>31.803821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>5.093963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>2.770778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>14.494660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>0.939225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CY</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LV</th>\n",
       "      <td>0.878124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT</th>\n",
       "      <td>1.022234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU</th>\n",
       "      <td>4.902144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HU</th>\n",
       "      <td>3.345774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL</th>\n",
       "      <td>1.557510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>7.425945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL</th>\n",
       "      <td>6.064111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>0.832088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>5.569470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>10.938901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK</th>\n",
       "      <td>5.854201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FI</th>\n",
       "      <td>7.938413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>0.933680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min Latency\n",
       "BE     2.871515\n",
       "BG     8.684864\n",
       "CZ     1.802406\n",
       "DK     2.938525\n",
       "DE     6.982521\n",
       "EE     1.791287\n",
       "IE     3.860732\n",
       "GR    31.803821\n",
       "ES     5.093963\n",
       "FR     2.770778\n",
       "HR    14.494660\n",
       "IT     0.939225\n",
       "CY          NaN\n",
       "LV     0.878124\n",
       "LT     1.022234\n",
       "LU     4.902144\n",
       "HU     3.345774\n",
       "MT          NaN\n",
       "NL     1.557510\n",
       "AT     7.425945\n",
       "PL     6.064111\n",
       "PT     0.832088\n",
       "RO     5.569470\n",
       "SI    10.938901\n",
       "SK     5.854201\n",
       "FI     7.938413\n",
       "SE     0.933680"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select 4 ASNs from matrix\n",
    "ASN_Country_Matrix_Optimal_df = ASN_Country_Matrix_df[list(ASNCombinations[CombinationIndex])]\n",
    "\n",
    "#Show minimal average latency to each country with 4 optimal locations\n",
    "min_latency_s = ASN_Country_Matrix_df.min(axis = 1)\n",
    "min_latency_df = pd.Series.to_frame(min_latency_s, 'min Latency')\n",
    "min_latency_df.index = EU_list\n",
    "min_latency_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bba474",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "After finding the average latency of every set of 4 possible hosting locations we found that the following set has the lowest average latency to all countries:\n",
    "\n",
    "- Netgroup A/S from Danmark with AS number: AS16245\n",
    "- QSC AG from Germany with AS number: AS15598\n",
    "- Prometeus di Daniela Agro from Italy with AS number: AS34971\n",
    "- Cyso Management B.V. from the Netherlands with AS number AS25151\n",
    "\n",
    "This set of AS has an average lowest latency to all countries of The table above shows the average latency of 6.73 ms. Therefor we recommend GNI to place servers in under those mentioned AS numbers. With this GNI can expect an average latency to each country as mentioned in the table above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d967ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
