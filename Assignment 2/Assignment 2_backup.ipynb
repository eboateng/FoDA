{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7c449a",
   "metadata": {},
   "source": [
    "# SEN163A - Fundamentals of Data Analytics\n",
    "# Assignment 2 - Large-scale Internet Data Analysis\n",
    "### Ir. Jacopo De Stefani - [J.deStefani@tudelft.nl](mailto:J.deStefani@tudelft.nl)\n",
    "### Joao Pizani Flor, M.Sc. - [J.p.pizaniflor@tudelft.nl](mailto:J.p.pizaniflor@tudelft.nl)\n",
    "\n",
    "### 05-03-2022\n",
    "## Group 2\n",
    "- Emmanuel M Boateng - '5617642'\n",
    "- Joost Oortwijn - '4593472'\n",
    "- Philip Busscher - ''4611993''\n",
    "- Floris Kool - ''4975243''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad1beb9",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook presents the results of our analysis of potential ASN's which can be used for hosting the mobile banking IT infrastructure for GNI Bank. Based on three datasets (described in chapter 1), we have idenified 4 locations which are, based on the available data, the best hosting options for GNI Bank. The indepth analysis consists of 4 parts and is shown in chapter 2. The final conclusion of our analysis is presented in chapter 3. In addition, we have identified different limitations to the available data which could decrease the usability of our recommendations in chapter 3, therefore these should be taken into account. These limitations are described in chapter 1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a1f8e1",
   "metadata": {},
   "source": [
    "# 1. Dataset description\n",
    "\n",
    "Short description of the 4 datasets used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76fa268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description of variables used accross the entire notebook\n",
    "\n",
    "#AS_df - Complete AS dataset as provided\n",
    "#P_df - Complete probe dataset as provided\n",
    "#EU_list - list of countries in EU\n",
    "#ipv4_df - Complete ip2location dataset\n",
    "    \n",
    "#as_probe_joined_df - Merge of AS and Probe dataset, from 2.1 on filtered to contain only type hosting and location from EU\n",
    "#AS_Probe_RIPE_df - Merge of AS and Probe dataset with probe ids in RIPE dataset and ASNs of type hosting and location from EU\n",
    "#display_df - Same as AS_Probe_RIPE_df with removed duplicate ASNs\n",
    "\n",
    "#RIPE_df - Complete useful contents of a single hour of ripe data (used for 2.1 & 2.2)\n",
    "#RIPE_HostAS_df - Entries of a single hour of ripe data with probe connected to an EU ASN with type host,\n",
    "    #From 2.2 on also filtered to only contain entries with destination address in EU\n",
    "    \n",
    "#Complete_ASN_Set - Set of ASNs of hosting type from EU and in complete RIPE dataset (Ended up being the same for each hour of data)\n",
    "#Complete_RIPE_Entries_df - Complete set of RIPE entries with probe ASN in eu and type host and destination in EU\n",
    "    #Can be loaded from all ripe files\n",
    "    #Also saved in RIPE_00-23.pkl (RIPE_00-5.pkl since we didn't read through the entire set)\n",
    "    \n",
    "#ASN_Country_Avg_df - Combination of each country, ASN and average ping\n",
    "#ASN_Country_Matrix_df - Combination of each country, ASN and average ping, with Country as index and ASN as column labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ec478",
   "metadata": {},
   "source": [
    "## 1.1 Opening the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5152fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import bz2\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipaddress\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36178185",
   "metadata": {},
   "source": [
    "### AS and Probe datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44140561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AS Dataset\n",
    "\n",
    "AS_Filename = 'data/AS_dataset.pkl'\n",
    "\n",
    "with open(AS_Filename, 'rb') as file:\n",
    "    \n",
    "    AS_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5585c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probe dataset\n",
    "\n",
    "Probe_Filename = 'data/probe_dataset.pkl'\n",
    "\n",
    "with open(Probe_Filename, 'rb') as file:\n",
    "    \n",
    "    P_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43d25438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU country codes retrieved from: https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:Country_codes\n",
    "EU_list = ['BE','BG','CZ','DK','DE','EE','IE','EL','ES','FR','HR','IT','CY','LV','LT','LU','HU','MT','NL','AT','PL','PT','RO','SI','SK','FI','SE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eb2560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the AS and Probe datasets\n",
    "as_probe_joined_df = pd.merge(P_df,AS_df, on='ASN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6fafaa",
   "metadata": {},
   "source": [
    "### IP2Location dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "488f08a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IP 2 Location dataset\n",
    "\n",
    "IP_Filename = \"data/IP2LOCATION-LITE-DB1.CSV\"\n",
    "\n",
    "ipv4_df = pd.read_csv(IP_Filename)\n",
    "\n",
    "ipv4_df.rename(columns = {'0':'ip_from', '16777215':'ip_to',\n",
    "                              '-':'country_code','-.1':'country_name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed46b72",
   "metadata": {},
   "source": [
    "### Single ripe file (Used for C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ripe dataset (Single file)\n",
    "\n",
    "#Option 1 decompressed file\n",
    "decomFilename = 'data/ping-2022-03-01T2300_decom'\n",
    "#decomFile     = open(decomFilename, 'rt')\n",
    "\n",
    "#Option 2 BZ2 file\n",
    "bz2Filename = 'data/ping-2022-03-01T0000.bz2'\n",
    "bz2File     = bz2.open(bz2Filename, 'rt')\n",
    "\n",
    "\n",
    "# List of tuples\n",
    "# https://stackoverflow.com/questions/28056171/how-to-build-and-fill-pandas-dataframe-from-for-loop\n",
    "tuple_list = []\n",
    "\n",
    "start  = time.time()\n",
    "\n",
    "#for line in bz2File:\n",
    "for line in bz2File:\n",
    "    \n",
    "    decoded_line = json.loads(line)\n",
    "    if \"af\" in decoded_line and \"dst_addr\" in decoded_line and \"prb_id\" in decoded_line and \"avg\" in decoded_line: \n",
    "        if decoded_line[\"af\"] == 4:\n",
    "            tuple_list.append((decoded_line[\"dst_addr\"],decoded_line[\"prb_id\"],decoded_line[\"avg\"]))\n",
    "\n",
    "            \n",
    "dur         = round(time.time() - start,2)\n",
    "print(\"Loading took: \"  + str(dur) + \" seconds\")\n",
    "print(\"Lines added to tuple: \" + str(len(tuple_list)))\n",
    "\n",
    "#finally close bz2File\n",
    "bz2File.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56bbc784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took: 6.05 seconds\n"
     ]
    }
   ],
   "source": [
    "#Load tuples data into dataframe\n",
    "start  = time.time()\n",
    "\n",
    "RIPE_df = pd.DataFrame(tuple_list)\n",
    "\n",
    "dur         = round(time.time() - start,2)\n",
    "print(\"Loading took: \"  + str(dur) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40bc05",
   "metadata": {},
   "source": [
    "### Complete ripe dataset from BZ2 files\n",
    "### Only loaded through 6 files due to time limitations\n",
    "Changed reading method to raw characters to save about 20% in loading time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a2bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changed 24 -> 6\n",
    "RIPE_Filenames = pd.date_range('2022-03-01', periods=6, freq='60min').strftime('D:/FoDa Data/ping-%Y-%m-%dT%H%M.bz2').tolist()\n",
    "\n",
    "Complete_ASN_List = []\n",
    "Complete_RIPE_Entries_df = pd.DataFrame({0:[], 1:[], 2:[], 'Country':[]})\n",
    "\n",
    "\n",
    "for filename in RIPE_Filenames:\n",
    "    #Read RIPE data\n",
    "    print(filename)\n",
    "    \n",
    "    start  = time.time()\n",
    "    with open(filename, 'rb') as fi:\n",
    "        decomp = bz2.BZ2Decompressor()\n",
    "        residue = b''\n",
    "        total_lines = 0\n",
    "        m = 0\n",
    "        tuple_list = []\n",
    "    \n",
    "        for data in iter(lambda: fi.read(100 * 1024), b''):\n",
    "            raw = residue + decomp.decompress(data) # process the raw data and  concatenate residual of the previous block to the beginning of the current raw data block\n",
    "            residue = b''\n",
    "            # process_data(current_block) => do the processing of the current data block\n",
    "            current_block = raw.split(b'\\n')\n",
    "            if raw[-1] != b'\\n':\n",
    "                residue = current_block.pop() # last line could be incomplete\n",
    "\n",
    "            for items in current_block:\n",
    "                df_dict = json.loads(items.decode('utf-8'))\n",
    "                if ('dst_addr' in df_dict) and (df_dict['af'] == 4) and (df_dict[\"avg\"] > 0):\n",
    "                    tuple_list.append((df_dict[\"dst_addr\"],df_dict[\"prb_id\"],df_dict[\"avg\"]))\n",
    "    \n",
    "    fi.close()\n",
    "    \n",
    "    Temp_RIPE_df = pd.DataFrame(tuple_list)\n",
    "    \n",
    "    #Get list of ASNs\n",
    "    unique_prbID = Temp_RIPE_df[1].unique()\n",
    "    \n",
    "    Temp_AS_Probe_RIPE_df = as_probe_joined_df.loc[as_probe_joined_df['prb_id'].isin(unique_prbID)]\n",
    "    \n",
    "    unique_ASNs = Temp_AS_Probe_RIPE_df['ASN'].unique()\n",
    "    Complete_ASN_List.extend(unique_ASNs)\n",
    "    \n",
    "    \n",
    "    #Get RIPE entries with dst addr in eu\n",
    "    Temp_RIPE_HostAS_df = Temp_RIPE_df.loc[Temp_RIPE_df[1].isin(Temp_AS_Probe_RIPE_df['prb_id'])]\n",
    "    \n",
    "    for i in Temp_RIPE_HostAS_df.index:\n",
    "        Temp_RIPE_HostAS_df.at[i, 0] = int(ipaddress.IPv4Address(Temp_RIPE_HostAS_df[0][i]))\n",
    "\n",
    "    Temp_RIPE_HostAS_df = Temp_RIPE_HostAS_df.sort_values(by=[0])\n",
    "    ipv4_df = ipv4_df.sort_values(by=[\"ip_from\"])\n",
    "\n",
    "    Dest_Addr_Countries = []\n",
    "    ripeindex = 0\n",
    "    ipindex = 0\n",
    "\n",
    "    while Temp_RIPE_HostAS_df.iat[ripeindex, 0] < ipv4_df.at[ipindex, \"ip_from\"]:\n",
    "        ripeindex = ripeindex + 1\n",
    "        Dest_Addr_Countries.append(\"-\")\n",
    "\n",
    "    for ipindex in ipv4_df.index:\n",
    "        while Temp_RIPE_HostAS_df.iat[ripeindex, 0] >= ipv4_df.at[ipindex, \"ip_from\"] and Temp_RIPE_HostAS_df.iat[ripeindex, 0] <= ipv4_df.at[ipindex, \"ip_to\"]:\n",
    "            Dest_Addr_Countries.append(ipv4_df.at[ipindex, \"country_code\"])\n",
    "            ripeindex = ripeindex + 1\n",
    "            if ripeindex >= len(Temp_RIPE_HostAS_df[0]):\n",
    "                break\n",
    "\n",
    "        if ripeindex >= len(Temp_RIPE_HostAS_df[0]):\n",
    "            break\n",
    "            \n",
    "    Temp_RIPE_HostAS_df[\"Country\"] = Dest_Addr_Countries\n",
    "    Temp_RIPE_HostAS_df = Temp_RIPE_HostAS_df.loc[Temp_RIPE_HostAS_df['Country'].isin(EU_list)]    \n",
    "    \n",
    "    \n",
    "    #Add entries to complete dataframe\n",
    "    frames = [Complete_RIPE_Entries_df, Temp_RIPE_HostAS_df]\n",
    "    Complete_RIPE_Entries_df = pd.concat(frames)\n",
    "    \n",
    "    dur         = round(time.time() - start,2)\n",
    "    print(\"Added \" + str(len(Temp_RIPE_HostAS_df[0])) + \" entries and \" + str(len(unique_ASNs)) + \" ASNs in \" + str(dur) + \" seconds\")\n",
    "    print()\n",
    "    \n",
    "\n",
    "#Remove duplicates\n",
    "Complete_ASN_Set = set(Complete_ASN_List)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936d5f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save filtered RIPE data to file\n",
    "print(\"Unique ASNs: \" + str(len(Complete_ASN_Set)))\n",
    "print(\"Ripe entries: \" + str(len(Complete_RIPE_Entries_df[0])))\n",
    "\n",
    "Complete_ASN_Set_df = pd.DataFrame(Complete_ASN_Set)\n",
    "\n",
    "Complete_ASN_Set_df.to_pickle(\"data/ASN_00-06.pkl\")\n",
    "\n",
    "Complete_RIPE_Entries_df.to_pickle(\"data/RIPE_00-06.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380eae4",
   "metadata": {},
   "source": [
    "### Complete ripe dataset from pkl file\n",
    "### Only loaded through 6 files due to time limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e7e3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probe dataset\n",
    "\n",
    "Ripe_Filename = 'data/RIPE_00-05.pkl'\n",
    "ASN_Filename = 'data/ASN_00-05.pkl'\n",
    "\n",
    "with open(Ripe_Filename, 'rb') as file:\n",
    "    \n",
    "    Complete_RIPE_Entries_df = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open(ASN_Filename, 'rb') as file:\n",
    "    \n",
    "    Complete_ASN_Set_df = pickle.load(file)\n",
    "\n",
    "Complete_ASN_Set = Complete_ASN_Set_df[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b47c3ba",
   "metadata": {},
   "source": [
    "More detailed description of data if needed (Can also be after opening each dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7448a884",
   "metadata": {},
   "source": [
    "## 1.2 Limitations in data (Question A)\n",
    "\n",
    "Evaluate if there are limitations in the provided datasets (AS and probe data set). If you find limitations, describe these and conjecture possible reasons, supported with data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18606f7f",
   "metadata": {},
   "source": [
    "### 1.2.1 Limitations in the AS and Probe dataset\n",
    "A limitation in the AS and probe dataset is the fact that according to the AS dataset there are 534 AS's that can be used for hosting in the EU. But when the AS data set is merged with the probe dataset the number of potential AS's has decreased to 339. An explanation for this is the fact that the probe dataset consists of significantly less AS's then the AS dataset (3652 compared to 60122). This can be seen as limitation as potential AS's are left out of the analysis eventhough these could be a interesting options for hosting the EU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb9b5f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AS_df.loc[(AS_df['type'] == 'hosting') & (AS_df['Country'].isin(EU_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2106b443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_probe_joined_df = pd.merge(P_df,AS_df, on='ASN')\n",
    "len(as_probe_joined_df.loc[(as_probe_joined_df['type'] == 'hosting') & (as_probe_joined_df['Country'].isin(EU_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0ab970a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AS55330     1\n",
       "AS31573     1\n",
       "AS200609    1\n",
       "AS200605    1\n",
       "AS51879     1\n",
       "           ..\n",
       "AS48290     1\n",
       "AS48295     1\n",
       "AS48303     1\n",
       "AS48360     1\n",
       "AS37485     1\n",
       "Name: ASN, Length: 60122, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AS_df['ASN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59d2d2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AS3320      351\n",
       "AS7922      334\n",
       "AS6830      333\n",
       "AS3215      243\n",
       "AS12322     210\n",
       "           ... \n",
       "AS8282        1\n",
       "AS12775       1\n",
       "AS199484      1\n",
       "AS199853      1\n",
       "AS49432       1\n",
       "Name: ASN, Length: 3652, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_df['ASN'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d5576",
   "metadata": {},
   "source": [
    "### 1.2.2 Limitation in the IP location dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b4417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a201acca",
   "metadata": {},
   "source": [
    "### 1.2.3 Limitations in the RIPE dataset\n",
    "\n",
    "When looking at the RIPE dataset, it was found that for some lines the IP destination addresses were missing. This was not the case for the Probe ID's and average round trip times as these were always included within the lines of the RIPE dataset. Below the number of missing values in the first 5 million lines are shown. When looking at the lines where the destination address is missing, it can be seen that these adresses are missing because there is no node or server name provided or known. Obviously this results in the lack of a destination address of that specific ping measurement. Due to the size of the available dataset this is not assumed as a limitation and the lines with missing destination address are simply skipped when opening the RIPE dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f941c7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11428 missing IP destination addresses in the first 5m lines of the RIPE dataset (for one hour)\n",
      "There are 0 missing probe ID's in the first 5m lines of the RIPE dataset (for one hour)\n",
      "There are 0 missing average round-trip time values in the first 5m lines of the RIPE dataset (for one hour)\n"
     ]
    }
   ],
   "source": [
    "bz2Filename = 'data/ping-2022-03-01T2300.bz2'\n",
    "bz2File_limitation = bz2.open(bz2Filename, 'rt') \n",
    "missing_adres = 0\n",
    "missing_probeID = 0\n",
    "missing_avg = 0\n",
    "line_number = 0\n",
    "\n",
    "for line in bz2File_limitation:\n",
    "    decoded_line = json.loads(line)\n",
    "    line_number += 1\n",
    "    if \"dst_addr\" not in decoded_line: \n",
    "        missing_adres += 1\n",
    "      \n",
    "    if \"prb_id\" not in decoded_line: \n",
    "        missing_probeID += 1\n",
    "        \n",
    "    if \"avg\" not in decoded_line: \n",
    "        missing_avg += 1\n",
    "           \n",
    "    if line_number > 5000000:\n",
    "        print('There are', missing_adres, 'missing IP destination addresses in the first 5m lines of the RIPE dataset (for one hour)')\n",
    "        print('There are', missing_probeID, 'missing probe ID\\'s in the first 5m lines of the RIPE dataset (for one hour)')\n",
    "        print('There are', missing_avg, 'missing average round-trip time values in the first 5m lines of the RIPE dataset (for one hour)')\n",
    "        break\n",
    "        \n",
    "bz2File_limitation.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15149a03",
   "metadata": {},
   "source": [
    "# 2 Analysis\n",
    "\n",
    "Short description of what is going to be analyzed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dbd4f1",
   "metadata": {},
   "source": [
    "## 2.1 AS (Question B)\n",
    "\n",
    "With the AS and probe data set, find the number m of AS’s that can be used for hosting in the EU\n",
    "and have probes in the RIPE data set. Sort the ASN’s in ascending order and include the first and last\n",
    "three in your report (number, name and country).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37ff34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the AS and Probe datasets\n",
    "as_probe_joined_df = pd.merge(P_df,AS_df, on='ASN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b948f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU country codes retrieved from: https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:Country_codes\n",
    "EU_list = ['BE','BG','CZ','DK','DE','EE','IE','EL','ES','FR','HR','IT','CY','LV','LT','LU','HU','MT','NL','AT','PL','PT','RO','SI','SK','FI','SE']\n",
    "\n",
    "# Filter data set for AS's that can be used for hosting in the EU\n",
    "as_probe_joined_df = as_probe_joined_df.loc[(as_probe_joined_df['type'] == 'hosting') & (as_probe_joined_df['Country'].isin(EU_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "010c4b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique probe IDs: 11597\n"
     ]
    }
   ],
   "source": [
    "#Get the unique number of probe IDs that are in the RIPE Data\n",
    "unique_prbID = RIPE_df[1].unique()\n",
    "\n",
    "print(\"Unique probe IDs: \" + str(len(unique_prbID)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cd78240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of probes connected to AS that can be used for hosting in the EU and are in the RIPE dataset: 234\n"
     ]
    }
   ],
   "source": [
    "#Filter the data set by only selecting the ASN's that have probes in the Ripe dataset\n",
    "AS_Probe_RIPE_df = as_probe_joined_df.loc[as_probe_joined_df['prb_id'].isin(unique_prbID)]\n",
    "\n",
    "#Sort by ASN\n",
    "AS_Probe_RIPE_df.sort_values(by=['ASN']).sort_values(by=['ASN'])\n",
    "\n",
    "print(\"Number of probes connected to AS that can be used for hosting in the EU and are in the RIPE dataset: \" + str(len(AS_Probe_RIPE_df[\"ASN\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87c861cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of AS that can be used for hosting in the EU and are in the RIPE dataset: 113\n"
     ]
    }
   ],
   "source": [
    "#Remove duplicate ASNs (Probes connected to same AS)\n",
    "display_df = AS_Probe_RIPE_df.drop_duplicates(subset=['ASN'])\n",
    "\n",
    "#Remove unused columns\n",
    "display_df = display_df.drop(columns=['prb_id', 'NumIPs', 'type'])\n",
    "\n",
    "#Sort by ASN\n",
    "display_df.insert(2, 'AS', display_df['ASN'].str.replace('AS', ''))\n",
    "display_df['AS'] = pd.to_numeric(display_df['AS'])\n",
    "display_df = display_df.sort_values('AS')\n",
    "\n",
    "#Print anwser to question B\n",
    "print(\"Number of AS that can be used for hosting in the EU and are in the RIPE dataset: \" + str(len(display_df[\"ASN\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91843c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASN</th>\n",
       "      <th>Country</th>\n",
       "      <th>AS</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6422</th>\n",
       "      <td>AS6724</td>\n",
       "      <td>DE</td>\n",
       "      <td>6724</td>\n",
       "      <td>Strato AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10262</th>\n",
       "      <td>AS8304</td>\n",
       "      <td>FR</td>\n",
       "      <td>8304</td>\n",
       "      <td>Ecritel SARL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8489</th>\n",
       "      <td>AS8315</td>\n",
       "      <td>NL</td>\n",
       "      <td>8315</td>\n",
       "      <td>Sentia Netherlands BV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ASN Country    AS                   Name\n",
       "6422   AS6724      DE  6724              Strato AG\n",
       "10262  AS8304      FR  8304           Ecritel SARL\n",
       "8489   AS8315      NL  8315  Sentia Netherlands BV"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First 3 probes\n",
    "display_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5994efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASN</th>\n",
       "      <th>Country</th>\n",
       "      <th>AS</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>AS201978</td>\n",
       "      <td>CY</td>\n",
       "      <td>201978</td>\n",
       "      <td>Osbil Technology Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9379</th>\n",
       "      <td>AS203944</td>\n",
       "      <td>LU</td>\n",
       "      <td>203944</td>\n",
       "      <td>NTT Luxembourg PSF S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>AS203953</td>\n",
       "      <td>DK</td>\n",
       "      <td>203953</td>\n",
       "      <td>Hiper A/S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ASN Country      AS                     Name\n",
       "8377  AS201978      CY  201978    Osbil Technology Ltd.\n",
       "9379  AS203944      LU  203944  NTT Luxembourg PSF S.A.\n",
       "2910  AS203953      DK  203953                Hiper A/S"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Last 3 probes\n",
    "display_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f65fd8",
   "metadata": {},
   "source": [
    "Description of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d61b4",
   "metadata": {},
   "source": [
    "## 2.2 Hosting location (Question C)\n",
    "For a single hour in the RIPE data set: find all valid entries where the probe has hosting type AS and\n",
    "the target IPv4 is from an EU country. Implement this in an efficient way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9d31427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries with probe connected to an EU as with type hosting: 704132\n"
     ]
    }
   ],
   "source": [
    "#Selects all entries in RIPE data with probe connected to EU as of type hosting\n",
    "RIPE_HostAS_df = RIPE_df.loc[RIPE_df[1].isin(AS_Probe_RIPE_df['prb_id'])]\n",
    "\n",
    "print(\"Entries with probe connected to an EU as with type hosting: \" + str(len(RIPE_HostAS_df[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5074bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert IP strings to IP integers\n",
    "for i in RIPE_HostAS_df.index:  \n",
    "    IP_Splitstring = RIPE_HostAS_df[0][i].split(\".\") \n",
    "    RIPE_HostAS_df.at[i, 0] = int(IP_Splitstring[0]) * 16581375 + int(IP_Splitstring[1]) * 65025 + int(IP_Splitstring[2]) * 255 + int(IP_Splitstring[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f063f134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP addresses not included in IP2location dataset: 79\n",
      "IP addresses linked to country: 704132\n"
     ]
    }
   ],
   "source": [
    "#Add country of dst_addr to RIPE_HostAS_df\n",
    "\n",
    "#Sorting the IP lists so we can check from low to high IPs\n",
    "RIPE_HostAS_df = RIPE_HostAS_df.sort_values(by=[0])\n",
    "ipv4_df = ipv4_df.sort_values(by=[\"ip_from\"])\n",
    "\n",
    "Dest_Addr_Countries = []\n",
    "ripeindex = 0\n",
    "ipindex = 0\n",
    "\n",
    "#Check if there are IP addresses lower than included in the IP2Location dataset\n",
    "while RIPE_HostAS_df.iat[ripeindex, 0] < ipv4_df.at[ipindex, \"ip_from\"]:\n",
    "    ripeindex = ripeindex + 1\n",
    "    Dest_Addr_Countries.append(\"-\")\n",
    "\n",
    "print(\"IP addresses not included in IP2location dataset: \" + str(ripeindex))\n",
    "\n",
    "#Check for each range of IP addresses in the IP2Location dataset which dst_addr IPs are present\n",
    "#Break loop early if the length of the RIPE dataset is reached\n",
    "for ipindex in ipv4_df.index:\n",
    "    while RIPE_HostAS_df.iat[ripeindex, 0] >= ipv4_df.at[ipindex, \"ip_from\"] and RIPE_HostAS_df.iat[ripeindex, 0] <= ipv4_df.at[ipindex, \"ip_to\"]:\n",
    "        Dest_Addr_Countries.append(ipv4_df.at[ipindex, \"country_code\"])\n",
    "        ripeindex = ripeindex + 1\n",
    "        if ripeindex >= len(RIPE_HostAS_df[0]):\n",
    "            break\n",
    "    \n",
    "    if ripeindex >= len(RIPE_HostAS_df[0]):\n",
    "        break\n",
    "\n",
    "print(\"IP addresses linked to country: \" + str(len(Dest_Addr_Countries)))\n",
    "\n",
    "#Add list for destination address location to dataframe\n",
    "RIPE_HostAS_df[\"Country\"] = Dest_Addr_Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c285f269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries with probe connected to an EU AS with type hosting and destination address within EU: 133653\n"
     ]
    }
   ],
   "source": [
    "#Remove entries not in EU\n",
    "RIPE_HostAS_df = RIPE_HostAS_df.loc[RIPE_HostAS_df['Country'].isin(EU_list)]\n",
    "\n",
    "print(\"Entries with probe connected to an EU AS with type hosting and destination address within EU: \" + str(len(RIPE_HostAS_df[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2cecc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13073077</th>\n",
       "      <td>34230351</td>\n",
       "      <td>1000114</td>\n",
       "      <td>5.056936</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14702804</th>\n",
       "      <td>34328463</td>\n",
       "      <td>55634</td>\n",
       "      <td>3.784625</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13797784</th>\n",
       "      <td>34350710</td>\n",
       "      <td>51992</td>\n",
       "      <td>11.232558</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11730303</th>\n",
       "      <td>34351632</td>\n",
       "      <td>18567</td>\n",
       "      <td>13.708424</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8886535</th>\n",
       "      <td>34376151</td>\n",
       "      <td>31065</td>\n",
       "      <td>4.453532</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15393251</th>\n",
       "      <td>34392634</td>\n",
       "      <td>13972</td>\n",
       "      <td>6.531589</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15310796</th>\n",
       "      <td>34392634</td>\n",
       "      <td>21994</td>\n",
       "      <td>0.608414</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138640</th>\n",
       "      <td>34392634</td>\n",
       "      <td>17138</td>\n",
       "      <td>17.750491</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15366304</th>\n",
       "      <td>34392634</td>\n",
       "      <td>6693</td>\n",
       "      <td>3.573891</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790751</th>\n",
       "      <td>34392634</td>\n",
       "      <td>21959</td>\n",
       "      <td>0.777758</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0        1          2 Country\n",
       "13073077  34230351  1000114   5.056936      FR\n",
       "14702804  34328463    55634   3.784625      FR\n",
       "13797784  34350710    51992  11.232558      FR\n",
       "11730303  34351632    18567  13.708424      FR\n",
       "8886535   34376151    31065   4.453532      FR\n",
       "15393251  34392634    13972   6.531589      FR\n",
       "15310796  34392634    21994   0.608414      FR\n",
       "1138640   34392634    17138  17.750491      FR\n",
       "15366304  34392634     6693   3.573891      FR\n",
       "7790751   34392634    21959   0.777758      FR"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RIPE_HostAS_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036634dc",
   "metadata": {},
   "source": [
    "Description of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01270a7",
   "metadata": {},
   "source": [
    "## 2.3 Latency (Question D)\n",
    "Move from using only an hour to the full day. It is advisable to store the raw results of each file. Then,\n",
    "using all processed files, calculate the average latency’s for each country-AS combination and store\n",
    "the results into one ncountries ×m matrix. If we could place one server in each country, what would the\n",
    "minimum average latency be for each country? (include in your report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e3de715a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took: 15.48 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>ASN</th>\n",
       "      <th>Average latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BE</td>\n",
       "      <td>AS50926</td>\n",
       "      <td>37.631237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BE</td>\n",
       "      <td>AS24961</td>\n",
       "      <td>15.303253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BE</td>\n",
       "      <td>AS39790</td>\n",
       "      <td>19.871554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BE</td>\n",
       "      <td>AS48854</td>\n",
       "      <td>20.909600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BE</td>\n",
       "      <td>AS62416</td>\n",
       "      <td>37.322580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country      ASN  Average latency\n",
       "0      BE  AS50926        37.631237\n",
       "1      BE  AS24961        15.303253\n",
       "2      BE  AS39790        19.871554\n",
       "3      BE  AS48854        20.909600\n",
       "4      BE  AS62416        37.322580"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the avg ping for each country-AS combination into a DF\n",
    "ASN_Country_Avg =[]\n",
    "start  = time.time()\n",
    "\n",
    "for country in EU_list:\n",
    "    \n",
    "    #Filter each country's ping values seperately into a dataframe\n",
    "    country_df = Complete_RIPE_Entries_df.loc[Complete_RIPE_Entries_df['Country'] == country]\n",
    "    \n",
    "    for ASN in Complete_ASN_Set:\n",
    "        \n",
    "        #Filter probe IDs for each seperate ASN\n",
    "        #There are more probes than ASs to calculate the average ping more accurately we use all probes\n",
    "        prb_df = as_probe_joined_df.loc[as_probe_joined_df['ASN'] == ASN]                            \n",
    "        \n",
    "        #Filter the ping data so it includes all probes from selected ASN and selected country\n",
    "        temp_df = country_df.loc[country_df[1].isin(prb_df['prb_id'])]\n",
    "        \n",
    "        #Create sum of all ASN - Country ping measurements\n",
    "        sumvalue = 0\n",
    "        i = 0\n",
    "        for pingvalue in temp_df[2]:\n",
    "            sumvalue = sumvalue + pingvalue\n",
    "            i = i+1\n",
    "        \n",
    "        #Check if there are ping measurements between AS - Country\n",
    "        #Calculate average when needed, enter nan when no data available\n",
    "        if not i == 0:\n",
    "            average = sumvalue/i\n",
    "            ASN_Country_Avg.append((country, ASN, average))\n",
    "        else:\n",
    "            ASN_Country_Avg.append((country, ASN, np.nan))\n",
    "            \n",
    "    \n",
    "\n",
    "#Load tuple list into dataframe\n",
    "ASN_Country_Avg_df = pd.DataFrame(ASN_Country_Avg)  \n",
    "ASN_Country_Avg_df.columns = ['Country','ASN','Average latency']\n",
    "\n",
    "dur         = round(time.time() - start,2)\n",
    "print(\"Loading took: \" + str(dur) + \" seconds\")\n",
    "\n",
    "ASN_Country_Avg_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a62f8ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AS12676</th>\n",
       "      <th>AS12824</th>\n",
       "      <th>AS12859</th>\n",
       "      <th>AS12876</th>\n",
       "      <th>AS12993</th>\n",
       "      <th>AS13287</th>\n",
       "      <th>AS15401</th>\n",
       "      <th>AS15598</th>\n",
       "      <th>AS15685</th>\n",
       "      <th>AS15817</th>\n",
       "      <th>...</th>\n",
       "      <th>AS61211</th>\n",
       "      <th>AS62000</th>\n",
       "      <th>AS62282</th>\n",
       "      <th>AS62416</th>\n",
       "      <th>AS6724</th>\n",
       "      <th>AS8304</th>\n",
       "      <th>AS8315</th>\n",
       "      <th>AS8560</th>\n",
       "      <th>AS8893</th>\n",
       "      <th>AS9211</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BE</th>\n",
       "      <td>11.156481</td>\n",
       "      <td>39.991050</td>\n",
       "      <td>10.863737</td>\n",
       "      <td>15.426602</td>\n",
       "      <td>47.130012</td>\n",
       "      <td>44.378539</td>\n",
       "      <td>32.022717</td>\n",
       "      <td>13.850941</td>\n",
       "      <td>7.245030</td>\n",
       "      <td>18.021685</td>\n",
       "      <td>...</td>\n",
       "      <td>16.165834</td>\n",
       "      <td>9.038073</td>\n",
       "      <td>30.031467</td>\n",
       "      <td>37.322580</td>\n",
       "      <td>22.105740</td>\n",
       "      <td>36.298499</td>\n",
       "      <td>14.670655</td>\n",
       "      <td>15.679276</td>\n",
       "      <td>14.239229</td>\n",
       "      <td>23.337293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>35.153710</td>\n",
       "      <td>58.282718</td>\n",
       "      <td>38.394082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.190486</td>\n",
       "      <td>39.580796</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.017865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.944770</td>\n",
       "      <td>45.340079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.703337</td>\n",
       "      <td>40.999549</td>\n",
       "      <td>34.482231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CZ</th>\n",
       "      <td>12.155558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.101986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.718502</td>\n",
       "      <td>16.392534</td>\n",
       "      <td>...</td>\n",
       "      <td>24.176706</td>\n",
       "      <td>19.323957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.145587</td>\n",
       "      <td>20.622238</td>\n",
       "      <td>37.162993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.712396</td>\n",
       "      <td>17.831068</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DK</th>\n",
       "      <td>21.028932</td>\n",
       "      <td>30.229738</td>\n",
       "      <td>16.442769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.615563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.171498</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.305757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.447622</td>\n",
       "      <td>21.598313</td>\n",
       "      <td>39.877256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.907005</td>\n",
       "      <td>15.833915</td>\n",
       "      <td>10.495258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>8.946247</td>\n",
       "      <td>26.107049</td>\n",
       "      <td>15.593103</td>\n",
       "      <td>16.046980</td>\n",
       "      <td>33.258409</td>\n",
       "      <td>38.762043</td>\n",
       "      <td>34.195170</td>\n",
       "      <td>6.402923</td>\n",
       "      <td>12.079615</td>\n",
       "      <td>13.481864</td>\n",
       "      <td>...</td>\n",
       "      <td>26.098151</td>\n",
       "      <td>17.739043</td>\n",
       "      <td>28.329440</td>\n",
       "      <td>46.813313</td>\n",
       "      <td>18.390852</td>\n",
       "      <td>32.461834</td>\n",
       "      <td>13.038404</td>\n",
       "      <td>9.949708</td>\n",
       "      <td>12.060789</td>\n",
       "      <td>11.322729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE</th>\n",
       "      <td>29.877902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.278537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.662063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.524693</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.343486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.275070</td>\n",
       "      <td>29.945309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.617919</td>\n",
       "      <td>27.866751</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IE</th>\n",
       "      <td>23.378083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.681111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.969252</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.853715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.950143</td>\n",
       "      <td>31.873797</td>\n",
       "      <td>37.075312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.522105</td>\n",
       "      <td>25.064629</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>37.244236</td>\n",
       "      <td>53.957538</td>\n",
       "      <td>39.916419</td>\n",
       "      <td>19.806524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.247730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.716897</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.723318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.346627</td>\n",
       "      <td>42.662035</td>\n",
       "      <td>32.945351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.003445</td>\n",
       "      <td>38.985322</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>17.536786</td>\n",
       "      <td>38.890575</td>\n",
       "      <td>22.038415</td>\n",
       "      <td>8.418621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.568624</td>\n",
       "      <td>11.139845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.252486</td>\n",
       "      <td>21.942327</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.859537</td>\n",
       "      <td>35.479169</td>\n",
       "      <td>36.457560</td>\n",
       "      <td>27.828333</td>\n",
       "      <td>19.639763</td>\n",
       "      <td>26.828019</td>\n",
       "      <td>16.838865</td>\n",
       "      <td>21.960819</td>\n",
       "      <td>19.611572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>27.264749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.070458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.138482</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.649413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.076026</td>\n",
       "      <td>30.307167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.682562</td>\n",
       "      <td>30.522726</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>22.790584</td>\n",
       "      <td>48.667874</td>\n",
       "      <td>29.156577</td>\n",
       "      <td>22.500879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.359357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.787628</td>\n",
       "      <td>26.775855</td>\n",
       "      <td>...</td>\n",
       "      <td>27.681067</td>\n",
       "      <td>23.862609</td>\n",
       "      <td>35.521259</td>\n",
       "      <td>43.450021</td>\n",
       "      <td>33.895069</td>\n",
       "      <td>34.324947</td>\n",
       "      <td>43.384664</td>\n",
       "      <td>20.937378</td>\n",
       "      <td>24.912657</td>\n",
       "      <td>27.808023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LV</th>\n",
       "      <td>32.813679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.065117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.612330</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.893471</td>\n",
       "      <td>6.074225</td>\n",
       "      <td>69.783176</td>\n",
       "      <td>23.627767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.755319</td>\n",
       "      <td>28.673834</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT</th>\n",
       "      <td>29.031484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.434072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.843465</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.684134</td>\n",
       "      <td>0.962713</td>\n",
       "      <td>63.056221</td>\n",
       "      <td>25.065034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.598317</td>\n",
       "      <td>29.810415</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU</th>\n",
       "      <td>9.234190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.502665</td>\n",
       "      <td>19.328962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.524476</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.774832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.628409</td>\n",
       "      <td>20.209175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.359777</td>\n",
       "      <td>13.253404</td>\n",
       "      <td>81.509597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HU</th>\n",
       "      <td>21.940945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.309768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.463250</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.515437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.753698</td>\n",
       "      <td>22.083017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.799678</td>\n",
       "      <td>25.457913</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL</th>\n",
       "      <td>10.555235</td>\n",
       "      <td>32.906078</td>\n",
       "      <td>3.956054</td>\n",
       "      <td>15.120629</td>\n",
       "      <td>28.498192</td>\n",
       "      <td>24.882956</td>\n",
       "      <td>33.073189</td>\n",
       "      <td>12.332609</td>\n",
       "      <td>13.152565</td>\n",
       "      <td>14.681946</td>\n",
       "      <td>...</td>\n",
       "      <td>23.120900</td>\n",
       "      <td>16.834387</td>\n",
       "      <td>25.038603</td>\n",
       "      <td>42.441659</td>\n",
       "      <td>15.595767</td>\n",
       "      <td>27.189984</td>\n",
       "      <td>2.921737</td>\n",
       "      <td>14.882831</td>\n",
       "      <td>13.496014</td>\n",
       "      <td>12.232562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>17.644899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.738341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.370345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.634680</td>\n",
       "      <td>14.397418</td>\n",
       "      <td>20.692552</td>\n",
       "      <td>...</td>\n",
       "      <td>23.574808</td>\n",
       "      <td>25.826203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.280156</td>\n",
       "      <td>23.849292</td>\n",
       "      <td>34.743347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.892911</td>\n",
       "      <td>20.206232</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL</th>\n",
       "      <td>23.458650</td>\n",
       "      <td>11.675359</td>\n",
       "      <td>24.576728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.977037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.221174</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.683342</td>\n",
       "      <td>8.336542</td>\n",
       "      <td>64.301939</td>\n",
       "      <td>23.887734</td>\n",
       "      <td>50.327315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.741717</td>\n",
       "      <td>21.621107</td>\n",
       "      <td>15.145991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>41.523144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.532760</td>\n",
       "      <td>28.094798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.892829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.901635</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.043481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.026435</td>\n",
       "      <td>51.278889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.363402</td>\n",
       "      <td>47.090848</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>31.659959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.605956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.522265</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.568085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.974408</td>\n",
       "      <td>37.814139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.945861</td>\n",
       "      <td>34.170549</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>25.277092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.935339</td>\n",
       "      <td>35.634717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.333607</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.844871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.286798</td>\n",
       "      <td>36.763185</td>\n",
       "      <td>51.965527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.478794</td>\n",
       "      <td>28.323591</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FI</th>\n",
       "      <td>29.659102</td>\n",
       "      <td>56.312709</td>\n",
       "      <td>30.469454</td>\n",
       "      <td>49.323947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.755030</td>\n",
       "      <td>...</td>\n",
       "      <td>52.776921</td>\n",
       "      <td>38.917979</td>\n",
       "      <td>13.040078</td>\n",
       "      <td>68.492196</td>\n",
       "      <td>33.318596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.835544</td>\n",
       "      <td>25.162159</td>\n",
       "      <td>29.958258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>20.293295</td>\n",
       "      <td>30.601647</td>\n",
       "      <td>19.668853</td>\n",
       "      <td>29.015272</td>\n",
       "      <td>14.882698</td>\n",
       "      <td>36.090634</td>\n",
       "      <td>30.980626</td>\n",
       "      <td>7.944353</td>\n",
       "      <td>15.596930</td>\n",
       "      <td>25.031450</td>\n",
       "      <td>...</td>\n",
       "      <td>17.741838</td>\n",
       "      <td>29.377312</td>\n",
       "      <td>5.915774</td>\n",
       "      <td>57.263140</td>\n",
       "      <td>32.920308</td>\n",
       "      <td>132.822488</td>\n",
       "      <td>10.876417</td>\n",
       "      <td>21.822272</td>\n",
       "      <td>16.455526</td>\n",
       "      <td>9.580071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AS12676    AS12824    AS12859    AS12876    AS12993    AS13287  \\\n",
       "Country                                                                     \n",
       "BE       11.156481  39.991050  10.863737  15.426602  47.130012  44.378539   \n",
       "BG       35.153710  58.282718  38.394082        NaN        NaN        NaN   \n",
       "CZ       12.155558        NaN  26.101986        NaN        NaN        NaN   \n",
       "DK       21.028932  30.229738  16.442769        NaN  34.615563        NaN   \n",
       "DE        8.946247  26.107049  15.593103  16.046980  33.258409  38.762043   \n",
       "EE       29.877902        NaN  36.278537        NaN   9.662063        NaN   \n",
       "IE       23.378083        NaN  25.681111        NaN        NaN        NaN   \n",
       "EL             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "ES       37.244236  53.957538  39.916419  19.806524        NaN   6.247730   \n",
       "FR       17.536786  38.890575  22.038415   8.418621        NaN  23.568624   \n",
       "HR       27.264749        NaN  47.070458        NaN        NaN        NaN   \n",
       "IT       22.790584  48.667874  29.156577  22.500879        NaN  24.359357   \n",
       "CY             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "LV       32.813679        NaN  31.065117        NaN        NaN        NaN   \n",
       "LT       29.031484        NaN  33.434072        NaN        NaN        NaN   \n",
       "LU        9.234190        NaN  12.502665  19.328962        NaN        NaN   \n",
       "HU       21.940945        NaN  28.309768        NaN        NaN        NaN   \n",
       "MT             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "NL       10.555235  32.906078   3.956054  15.120629  28.498192  24.882956   \n",
       "AT       17.644899        NaN  20.738341        NaN  35.370345        NaN   \n",
       "PL       23.458650  11.675359  24.576728        NaN  22.977037        NaN   \n",
       "PT       41.523144        NaN  46.532760  28.094798        NaN  15.892829   \n",
       "RO       31.659959        NaN  37.605956        NaN        NaN        NaN   \n",
       "SI       25.277092        NaN  36.935339  35.634717        NaN        NaN   \n",
       "SK             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "FI       29.659102  56.312709  30.469454  49.323947        NaN        NaN   \n",
       "SE       20.293295  30.601647  19.668853  29.015272  14.882698  36.090634   \n",
       "\n",
       "           AS15401    AS15598    AS15685    AS15817  ...    AS61211  \\\n",
       "Country                                              ...              \n",
       "BE       32.022717  13.850941   7.245030  18.021685  ...  16.165834   \n",
       "BG             NaN        NaN  24.190486  39.580796  ...        NaN   \n",
       "CZ             NaN        NaN   2.718502  16.392534  ...  24.176706   \n",
       "DK             NaN        NaN        NaN  23.171498  ...        NaN   \n",
       "DE       34.195170   6.402923  12.079615  13.481864  ...  26.098151   \n",
       "EE             NaN        NaN        NaN  36.524693  ...        NaN   \n",
       "IE             NaN        NaN        NaN  28.969252  ...        NaN   \n",
       "EL             NaN        NaN        NaN        NaN  ...        NaN   \n",
       "ES             NaN        NaN        NaN  38.716897  ...        NaN   \n",
       "FR       11.139845        NaN  16.252486  21.942327  ...        NaN   \n",
       "HR             NaN        NaN        NaN  27.138482  ...        NaN   \n",
       "IT             NaN        NaN  18.787628  26.775855  ...  27.681067   \n",
       "CY             NaN        NaN        NaN        NaN  ...        NaN   \n",
       "LV             NaN        NaN        NaN  33.612330  ...        NaN   \n",
       "LT             NaN        NaN        NaN  33.843465  ...        NaN   \n",
       "LU             NaN        NaN        NaN  13.524476  ...        NaN   \n",
       "HU             NaN        NaN        NaN  25.463250  ...        NaN   \n",
       "MT             NaN        NaN        NaN        NaN  ...        NaN   \n",
       "NL       33.073189  12.332609  13.152565  14.681946  ...  23.120900   \n",
       "AT             NaN  10.634680  14.397418  20.692552  ...  23.574808   \n",
       "PL             NaN        NaN        NaN  26.221174  ...        NaN   \n",
       "PT             NaN        NaN        NaN  44.901635  ...        NaN   \n",
       "RO             NaN        NaN        NaN  33.522265  ...        NaN   \n",
       "SI             NaN        NaN        NaN  27.333607  ...        NaN   \n",
       "SK             NaN        NaN        NaN        NaN  ...        NaN   \n",
       "FI             NaN        NaN        NaN  31.755030  ...  52.776921   \n",
       "SE       30.980626   7.944353  15.596930  25.031450  ...  17.741838   \n",
       "\n",
       "           AS62000    AS62282    AS62416     AS6724      AS8304     AS8315  \\\n",
       "Country                                                                      \n",
       "BE        9.038073  30.031467  37.322580  22.105740   36.298499  14.670655   \n",
       "BG       38.017865        NaN  66.944770  45.340079         NaN        NaN   \n",
       "CZ       19.323957        NaN  52.145587  20.622238   37.162993        NaN   \n",
       "DK       31.305757        NaN  54.447622  21.598313   39.877256        NaN   \n",
       "DE       17.739043  28.329440  46.813313  18.390852   32.461834  13.038404   \n",
       "EE       40.343486        NaN  70.275070  29.945309         NaN        NaN   \n",
       "IE       23.853715        NaN  46.950143  31.873797   37.075312        NaN   \n",
       "EL             NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "ES       28.723318        NaN  19.346627  42.662035   32.945351        NaN   \n",
       "FR        7.859537  35.479169  36.457560  27.828333   19.639763  26.828019   \n",
       "HR       30.649413        NaN  61.076026  30.307167         NaN        NaN   \n",
       "IT       23.862609  35.521259  43.450021  33.895069   34.324947  43.384664   \n",
       "CY             NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "LV       37.893471   6.074225  69.783176  23.627767         NaN        NaN   \n",
       "LT       35.684134   0.962713  63.056221  25.065034         NaN        NaN   \n",
       "LU        9.774832        NaN  44.628409  20.209175         NaN        NaN   \n",
       "HU       28.515437        NaN  63.753698  22.083017         NaN        NaN   \n",
       "MT             NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "NL       16.834387  25.038603  42.441659  15.595767   27.189984   2.921737   \n",
       "AT       25.826203        NaN  52.280156  23.849292   34.743347        NaN   \n",
       "PL       47.683342   8.336542  64.301939  23.887734   50.327315        NaN   \n",
       "PT       35.043481        NaN   1.026435  51.278889         NaN        NaN   \n",
       "RO       40.568085        NaN  67.974408  37.814139         NaN        NaN   \n",
       "SI       30.844871        NaN  58.286798  36.763185   51.965527        NaN   \n",
       "SK             NaN        NaN        NaN        NaN         NaN        NaN   \n",
       "FI       38.917979  13.040078  68.492196  33.318596         NaN        NaN   \n",
       "SE       29.377312   5.915774  57.263140  32.920308  132.822488  10.876417   \n",
       "\n",
       "            AS8560     AS8893     AS9211  \n",
       "Country                                   \n",
       "BE       15.679276  14.239229  23.337293  \n",
       "BG       31.703337  40.999549  34.482231  \n",
       "CZ       11.712396  17.831068        NaN  \n",
       "DK       21.907005  15.833915  10.495258  \n",
       "DE        9.949708  12.060789  11.322729  \n",
       "EE       33.617919  27.866751        NaN  \n",
       "IE       25.522105  25.064629        NaN  \n",
       "EL             NaN        NaN        NaN  \n",
       "ES       34.003445  38.985322        NaN  \n",
       "FR       16.838865  21.960819  19.611572  \n",
       "HR       22.682562  30.522726        NaN  \n",
       "IT       20.937378  24.912657  27.808023  \n",
       "CY             NaN        NaN        NaN  \n",
       "LV       29.755319  28.673834        NaN  \n",
       "LT       28.598317  29.810415        NaN  \n",
       "LU        7.359777  13.253404  81.509597  \n",
       "HU       17.799678  25.457913        NaN  \n",
       "MT             NaN        NaN        NaN  \n",
       "NL       14.882831  13.496014  12.232562  \n",
       "AT       16.892911  20.206232        NaN  \n",
       "PL       21.741717  21.621107  15.145991  \n",
       "PT       41.363402  47.090848        NaN  \n",
       "RO       29.945861  34.170549        NaN  \n",
       "SI       32.478794  28.323591        NaN  \n",
       "SK             NaN        NaN        NaN  \n",
       "FI       28.835544  25.162159  29.958258  \n",
       "SE       21.822272  16.455526   9.580071  \n",
       "\n",
       "[27 rows x 113 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display Country-AS-AVerage dataframe as a matrix\n",
    "\n",
    "ASN_Country_Avg_df = ASN_Country_Avg_df.iloc[:, 1:] # asn and latency\n",
    "df_groupby = ASN_Country_Avg_df.groupby('ASN')['Average latency'].apply(list)\n",
    "\n",
    "new_dftesttest = np.zeros((len(df_groupby), len(df_groupby[0])))\n",
    "for i in range(len(df_groupby)):\n",
    "    for j in range(len(df_groupby[0])):\n",
    "        new_dftesttest[i,j] = df_groupby[i][j]\n",
    "\n",
    "df_groupby.index\n",
    "ASN_Country_Matrix_df = pd.DataFrame(new_dftesttest.transpose())   \n",
    "\n",
    "column_list = list(df_groupby.index)\n",
    "ASN_Country_Matrix_df.columns=column_list\n",
    "ASN_Country_Matrix_df.insert(0,'Country', EU_list)\n",
    "ASN_Country_Matrix_df.set_index('Country')\n",
    "#ASN_Country_Matrix_df.insert(0, 'Country', EU_list)\n",
    "#ASN_Country_Matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4ed7edd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/wtyzdplx1712rf3p12f4blkm0000gn/T/ipykernel_6229/966997821.py:6: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  min_latency_s = ASN_Country_Matrix_df.min(axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>min Latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BE</td>\n",
       "      <td>2.766055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BG</td>\n",
       "      <td>8.660445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CZ</td>\n",
       "      <td>1.813910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DK</td>\n",
       "      <td>2.444158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE</td>\n",
       "      <td>6.402923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EE</td>\n",
       "      <td>3.619814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IE</td>\n",
       "      <td>3.678095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ES</td>\n",
       "      <td>5.084935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FR</td>\n",
       "      <td>2.846752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HR</td>\n",
       "      <td>14.492215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IT</td>\n",
       "      <td>0.897590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LV</td>\n",
       "      <td>6.074225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LT</td>\n",
       "      <td>0.962713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LU</td>\n",
       "      <td>4.861103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HU</td>\n",
       "      <td>2.855117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NL</td>\n",
       "      <td>1.567462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AT</td>\n",
       "      <td>7.050497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PL</td>\n",
       "      <td>6.071104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PT</td>\n",
       "      <td>0.827788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RO</td>\n",
       "      <td>6.633921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SI</td>\n",
       "      <td>10.947998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SK</td>\n",
       "      <td>5.985446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FI</td>\n",
       "      <td>7.908253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SE</td>\n",
       "      <td>0.956584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  min Latency\n",
       "0       BE     2.766055\n",
       "1       BG     8.660445\n",
       "2       CZ     1.813910\n",
       "3       DK     2.444158\n",
       "4       DE     6.402923\n",
       "5       EE     3.619814\n",
       "6       IE     3.678095\n",
       "7       EL          NaN\n",
       "8       ES     5.084935\n",
       "9       FR     2.846752\n",
       "10      HR    14.492215\n",
       "11      IT     0.897590\n",
       "12      CY          NaN\n",
       "13      LV     6.074225\n",
       "14      LT     0.962713\n",
       "15      LU     4.861103\n",
       "16      HU     2.855117\n",
       "17      MT          NaN\n",
       "18      NL     1.567462\n",
       "19      AT     7.050497\n",
       "20      PL     6.071104\n",
       "21      PT     0.827788\n",
       "22      RO     6.633921\n",
       "23      SI    10.947998\n",
       "24      SK     5.985446\n",
       "25      FI     7.908253\n",
       "26      SE     0.956584"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the minimum latency for each country\n",
    "\n",
    "#Still needs to be done\n",
    "\n",
    "\n",
    "min_latency_s = ASN_Country_Matrix_df.min(axis = 1)\n",
    "#min_latency_df = pd.Series.to_frame(min_latency_s, 'min Latency')\n",
    "min_latency_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc7a5f5",
   "metadata": {},
   "source": [
    "Description of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee912e63",
   "metadata": {},
   "source": [
    "## 2.4 Optimal server locations (Question E)\n",
    "Since we are only allowed to place four servers, determine the best four datacenters based on the total\n",
    "latency for all countries. Report your findings and your procedure to obtain them. Also include the\n",
    "average latency for each country.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9c13af3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 20, 18, 9, 5, 8, 9, 4, 2, 4, 9, 18, 8, 18, 14, 3, 0, 9, 2, 15, 26, 5, 2, 3, 18, 26, 3, 18, 18, 26, 26, 3, 21, 18, 4, 16, 18, 18, 18, 15, 18, 4, 26, 8, 9, 16, 26, 11, 26, 0, 18, 11, 18, 21, 18, 4, 0, 4, 11, 18, 9, 9, 2, 21, 6, 21, 2, 9, 18, 18, 22, 2, 0, 26, 16, 0, 9, 26, 18, 15, 26, 26, 18, 2, 18, 26, 20, 18, 20, 3, 5, 18, 4, 8, 15, 3, 26, 26, 9, 18, 3, 15, 26, 0, 9, 14, 21, 18, 9, 18, 15, 4, 26]\n"
     ]
    }
   ],
   "source": [
    "#Code...\n",
    "\n",
    "#ASN_Country_Matrix_df.insert(0, 'Country', EU_list)\n",
    "ASN_latency_df = ASN_Country_Matrix_df.iloc[:, 1:]\n",
    "results_byASN = ASN_latency_df.idxmin(axis=0)\n",
    "ASN_min_index = list(results_byASN)\n",
    "print(ASN_min_index)\n",
    "result_byCountry = ASN_latency_df.idxmin(axis=1)\n",
    "Country_min_index = list(result_byCountry)\n",
    "#print(Country_min_index)\n",
    "bestASN=[]\n",
    "newList = []\n",
    "\n",
    "# In this area, we get the index the minimum for each country and \n",
    "#the minuimum for each ASN column.\n",
    "# Cross checking the two should give us a list of possible countries with \n",
    "# minimum latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034dc37-63de-4137-a98f-43a15135c7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5e91f33",
   "metadata": {},
   "source": [
    "0Description of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2837d87",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "... \n",
    "add code if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c9b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c760888d",
   "metadata": {},
   "source": [
    "# Stuff we saved, delete if not used in final version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fa9cd",
   "metadata": {},
   "source": [
    "## Part C Alternative Approach reading all the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import bz2\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas\n",
    "import io\n",
    "import datetime\n",
    "import socket\n",
    "import struct\n",
    "\n",
    "def ip2int(addr):\n",
    "    return struct.unpack(\"!I\", socket.inet_aton(addr))[0]\n",
    "\n",
    "with open('data/AS_dataset.pkl', 'rb') as file:\n",
    "    AS_df = pickle.load(file)\n",
    "    \n",
    "with open('data/probe_dataset.pkl', 'rb') as file:    \n",
    "    P_df = pickle.load(file)\n",
    "    \n",
    "decomFilename = 'data/ping-2022-03-01T2300.bz2'\n",
    "#decomFile     = bz2.open(decomFilename, 'rt')   \n",
    "merged_df = P_df.merge(AS_df)\n",
    "\n",
    "ipv4_df = pandas.read_csv(\"data/IP2LOCATION-LITE-DB1.CSV\")\n",
    "ipv4_df.rename(columns = {'0':'ip_from', '16777215':'ip_to',\n",
    "                              '-':'country_code','-.1':'country_name'}, inplace = True)\n",
    "\n",
    "\n",
    "EU_Countries = [\"AT\",\"BE\",\"HR\",\"CY\",\"CZ\",\"DK\",\"EE\",\"FI\",\"FR\",\"GR\",\"DE\",\"HU\",\n",
    "                \"IE\",\"IT\",\"LV\",\"LT\",\"LU\",\"MT\",\"NL\",\"PL\",\"PT\",\"RO\",\"SK\",\"SI\",\n",
    "                \"ES\",\"SE\"]\n",
    "\n",
    "EU_data = merged_df[merged_df['Country'].isin(EU_Countries)]\n",
    "EU_Hosting = EU_data[EU_data['type'] == 'hosting']\n",
    "\n",
    "\n",
    "\n",
    "merged_df.insert(2, 'AS', merged_df['ASN'].str.replace('AS',''))\n",
    "merged_df['AS'] = pandas.to_numeric(merged_df['AS'])\n",
    "merged_df['prb_id'] = pandas.to_numeric(merged_df['prb_id'])\n",
    "\n",
    "\n",
    "merged_df_sorted = merged_df.sort_values('AS')\n",
    "df_HostingAS = merged_df[merged_df['type'] == 'hosting']\n",
    "\n",
    "ipv4_df.head()\n",
    "tpl = ipv4_df.loc[:, 'ip_from':'ip_to'].apply(tuple, 1).tolist()\n",
    "idx = pandas.IntervalIndex.from_tuples(tpl, 'both')\n",
    "\n",
    "t0 = time.time()\n",
    "time.sleep(0.000001)\n",
    "with open(decomFilename, 'rb') as file:\n",
    "    decomp = bz2.BZ2Decompressor()\n",
    "    residue = b''\n",
    "    total_lines = 0\n",
    "    m = 0\n",
    "    checked = []\n",
    "    #102400 Bytes = 102.4 KB (in decimal)\n",
    "    #102400 Bytes = 100 KB (in binary)\n",
    "    #Iterate over RIPE data in  100 KB chunks \n",
    "    for data in iter(lambda: file.read(100 * 1024), b''):\n",
    "        # process the raw data and  concatenate residual of the previous block \n",
    "        #to the beginning of the current raw data block\n",
    "        raw = residue + decomp.decompress(data) \n",
    "        residue = b''\n",
    "        ## process_data(current_block) => do the processing of the \n",
    "        ##current data block\n",
    "        current_block = raw.split(b'\\n')\n",
    "        if raw[-1] != b'\\n':\n",
    "            residue = current_block.pop() # last line could be incomplete\n",
    "        ##Process all data in the current block to check    \n",
    "        for items in current_block:\n",
    "            df_dict = json.loads(items.decode('utf-8'))\n",
    "            if ('dst_addr' in df_dict) and (df_dict['af'] == 4):# and (ip2int(df_dict['dst_addr'])>0:\n",
    "                ##convert to interger\n",
    "                df_ip = ip2int(df_dict['dst_addr'])\n",
    "                \n",
    "                if df_ip > 0: #and (df_dict['prb_id'] not in checked)): # certain lines have 0.0.0.0 IP\n",
    "                    loc = idx.get_loc(df_ip)\n",
    "                    if ((ipv4_df.loc[loc,'country_code'] in EU_Countries) and (df_dict['prb_id'] not in checked)):\n",
    "                        #if len(EU_Hosting[EU_Hosting['prb_id'] == df_dict['prb_id']])!=0:\n",
    "                            #print(df_HostingAS[df_HostingAS['prb_id'] == df_dict['prb_id']])\n",
    "                        m +=1 ## increment count\n",
    "                       ##create a list of probes that could be used later                     \n",
    "                        checked.append(df_dict['prb_id']) \n",
    "        total_lines += len(current_block)\n",
    "    total_lines += 1\n",
    "\n",
    "print(\"Total processing time: \",(time.time() - t0))\n",
    "print(\"Total number of probe entries with hosting type AS and EU target in RIPE is %i\" %(m))\n",
    "fi.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cae8c6",
   "metadata": {},
   "source": [
    "## Alternative solution to D (Emmanuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "04518d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BE</td>\n",
       "      <td>AS12859</td>\n",
       "      <td>85.256193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BE</td>\n",
       "      <td>AS25596</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BE</td>\n",
       "      <td>AS15598</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BE</td>\n",
       "      <td>AS203953</td>\n",
       "      <td>12.915613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BE</td>\n",
       "      <td>AS51815</td>\n",
       "      <td>3.754592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1          2\n",
       "0  BE   AS12859  85.256193\n",
       "1  BE   AS25596  -1.000000\n",
       "2  BE   AS15598        NaN\n",
       "3  BE  AS203953  12.915613\n",
       "4  BE   AS51815   3.754592"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We want a matrix of 26 countries * 113 ASNs (For a single file, should be more for 24 files)\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import bz2\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas\n",
    "import io\n",
    "import datetime\n",
    "import socket\n",
    "import struct\n",
    "from ip2geotools.databases.noncommercial import HostIP #gets the country code from ip\n",
    "\n",
    "def ip2int(addr):\n",
    "    return struct.unpack(\"!I\", socket.inet_aton(addr))[0]\n",
    "\n",
    "\n",
    "with open('data/AS_dataset.pkl', 'rb') as file:\n",
    "    AS_df = pickle.load(file)\n",
    "    \n",
    "with open('data/probe_dataset.pkl', 'rb') as file:    \n",
    "    P_df = pickle.load(file)\n",
    "    \n",
    "decomFilename = 'data/ping-2022-03-01T2300.bz2'\n",
    "#decomFile     = bz2.open(decomFilename, 'rt')   \n",
    "merged_df = P_df.merge(AS_df)\n",
    "probes = merged_df['prb_id'].tolist()\n",
    "print(type(probes))\n",
    "\n",
    "ipv4_df = pandas.read_csv(\"data/IP2LOCATION-LITE-DB1.CSV\")\n",
    "ipv4_df.rename(columns = {'0':'ip_from', '16777215':'ip_to',\n",
    "                              '-':'country_code','-.1':'country_name'}, inplace = True)\n",
    "\n",
    "\n",
    "EU_Countries = [\"AT\",\"BE\",\"HR\",\"CY\",\"CZ\",\"DK\",\"EE\",\"FI\",\"FR\",\"GR\",\"DE\",\"HU\",\n",
    "                \"IE\",\"IT\",\"LV\",\"LT\",\"LU\",\"MT\",\"NL\",\"PL\",\"PT\",\"RO\",\"SK\",\"SI\",\n",
    "                \"ES\",\"SE\"]\n",
    "\n",
    "EU_data = merged_df[merged_df['Country'].isin(EU_Countries)]\n",
    "EU_Hosting = EU_data[EU_data['type'] == 'hosting']\n",
    "\n",
    "merged_df.insert(2, 'AS', merged_df['ASN'].str.replace('AS',''))\n",
    "merged_df['AS'] = pandas.to_numeric(merged_df['AS'])\n",
    "merged_df['prb_id'] = pandas.to_numeric(merged_df['prb_id'])\n",
    "\n",
    "df_HostingAS = merged_df[merged_df['type'] == 'hosting']\n",
    "\n",
    "ipv4_df.head()\n",
    "tpl = ipv4_df.loc[:, 'ip_from':'ip_to'].apply(tuple, 1).tolist()\n",
    "idx = pandas.IntervalIndex.from_tuples(tpl, 'both')\n",
    "    \n",
    "l =pandas.date_range('2022-03-01', periods=24, freq='60min').strftime('data/ping-%Y-%m-%dT%H%M.bz2').tolist()\n",
    "#print(l)\n",
    "m = 0\n",
    "data = []\n",
    "df = []\n",
    "for dataset in l:\n",
    "    decomFilename = dataset\n",
    "    print(decomFilename)\n",
    "    tstamp = str(decomFilename.strip('.bz2')[-5:])\n",
    "    #print(tstamp)\n",
    "\n",
    "    with open(decomFilename, 'rb') as fi:\n",
    "        decomp = bz2.BZ2Decompressor()\n",
    "        residue = b''\n",
    "        total_lines = 0\n",
    "        \n",
    "        for data in iter(lambda: fi.read(100 * 1024), b''):\n",
    "            raw = residue + decomp.decompress(data) # process the raw data and  concatenate residual of the previous block to the beginning of the current raw data block\n",
    "            residue = b''\n",
    "            # process_data(current_block) => do the processing of the current data block\n",
    "            current_block = raw.split(b'\\n')\n",
    "            if raw[-1] != b'\\n':\n",
    "                residue = current_block.pop() # last line could be incomplete\n",
    "            for items in current_block:\n",
    "                df_dict = json.loads(items.decode('utf-8'))\n",
    "                if ('dst_addr' in df_dict and df_dict['dst_addr']!= '0.0.0.0' and df_dict['af'] == 4 and df_dict['avg']>0):\n",
    "                    df_ip = ip2int(df_dict['dst_addr'])\n",
    "                    loc = idx.get_loc(df_ip)\n",
    "                    if ((ipv4_df.loc[loc,'country_code'] in EU_Countries) and df_dict['prb_id'] in probes):\n",
    "                        res = {key: df_dict[key] for key in df_dict.keys()\n",
    "                                   & {'avg','prb_id'}}\n",
    "                        res['Country'] = ipv4_df.loc[loc,'country_code']\n",
    "                        res['t'] = tstamp\n",
    "                        #print(res)\n",
    "                        df_line = pandas.DataFrame.from_dict(res, orient='index')\n",
    "                        df.append(df_line)\n",
    "                \n",
    "            total_lines += len(current_block)\n",
    "        total_lines += 1\n",
    "        if total_lines > 1000:\n",
    "            print('i should take a break')\n",
    "            break\n",
    "            \n",
    "    df.groupby('Country', as_index=False)['avg'].mean() \n",
    "    m+=1\n",
    "    if m>=1:\n",
    "        print('Taking a break')\n",
    "        break\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
